{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHCmAzXudVmUvTypSy4QDt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nogbazghi/CSC8980/blob/main/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0iOQL9uA99K"
      },
      "source": [
        "Nahom Ogbazghi\n",
        "002052292"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425cf5da-dab3-4328-a150-3d271ba970f5"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuoF7Y5vA73_",
        "outputId": "e4efb5ef-f4c0-4c5e-ada7-5b15e782d8aa"
      },
      "source": [
        "!mkdir -p data\n",
        "!wget -nc http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip -P data\n",
        "!unzip -n -d data data/trainingandtestdata.zip"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "URL transformed to HTTPS due to an HSTS policy\n",
            "File ‘data/trainingandtestdata.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  data/trainingandtestdata.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7zF9YMJDJIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8811856a-c925-48f0-c739-944fb5b16b9e"
      },
      "source": [
        "import pandas as pd\n",
        "# Supress deprecation warnings\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "\n",
        "tweets = pd.read_csv(\"./data/testdata.manual.2009.06.14.csv\", delimiter=',', header=None, names=['polarity', 'id', 'date', 'query', 'user', 'text'])\n",
        "\n",
        "# Map for readable classnames\n",
        "class_names = [\"Negative\", \"Positive\"]\n",
        "\n",
        "# removed neutral\n",
        "filteredTweets = tweets[tweets.polarity != 2]\n",
        "#relabeled positive from 4 to 1\n",
        "filteredTweets['polarity'].replace({4: 1}, inplace=True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlAsv6iphyYe",
        "outputId": "24a44042-fecc-46a1-d75c-7743ff3393e1"
      },
      "source": [
        "filteredTweets.shape\n",
        "filteredTweets.polarity.value_counts()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    182\n",
              "0    177\n",
              "Name: polarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6tZoWyJw3R6"
      },
      "source": [
        "1. Take the positive and the negative tweets only. Use Sklearn to split the dataset in 80%\n",
        "training, 20% testing splits. Provide a nicely formatted summary of these splits,\n",
        "containing their size) (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIFSi0IxF3X7"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSrd55cOF4L9"
      },
      "source": [
        "vocab_size=10000\n",
        "vectorizer = TfidfVectorizer(max_features=vocab_size)\n",
        "vectors = vectorizer.fit_transform(filteredTweets.text)\n",
        "word_id_pair = vectorizer.vocabulary_\n",
        "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "# words_df.head()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3YPpb34itHw"
      },
      "source": [
        "X = words_df\n",
        "y = filteredTweets.polarity"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuTrr3-vZYAT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "randomSeed = 2361\n",
        "\n",
        "# a 80% training, 20 test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=randomSeed)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgcJbLi_zGPF",
        "outputId": "a0491216-5191-4184-e911-0b2673d94397"
      },
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "training_indexes = y_train.index.values.tolist()\n",
        "testing_indexes = y_test.index.values.tolist()\n",
        "training_summary = \"\"\n",
        "testing_summary = \"\"\n",
        "training_positive = 0\n",
        "testing_positive = 0\n",
        "for index, row in filteredTweets.iterrows():\n",
        "  if index in training_indexes:\n",
        "    training_summary += row.text + \" \"\n",
        "    if row.polarity == 1:\n",
        "      training_positive += 1\n",
        "  else:\n",
        "    testing_summary += row.text + \" \"\n",
        "    if row.polarity == 1:\n",
        "      testing_positive += 1\n",
        "\n",
        "training_data = [\"Training\", training_summary[:65], len(training_indexes), training_positive, len(training_indexes) - training_positive]\n",
        "testing_data = [\"Testing\", testing_summary[:65], len(testing_indexes), testing_positive, len(testing_indexes) - testing_positive]\n",
        "data = [training_data, testing_data]\n",
        "\n",
        "print(tabulate(data, headers=[\"Data Type\", \"Text Summary\", \"Amount of Items\", \"Positive Count\", \"Negative Count\"], tablefmt=\"fancy_grid\"))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "╒═════════════╤══════════════════════════════════════════════════════════════════╤═══════════════════╤══════════════════╤══════════════════╕\n",
            "│ Data Type   │ Text Summary                                                     │   Amount of Items │   Positive Count │   Negative Count │\n",
            "╞═════════════╪══════════════════════════════════════════════════════════════════╪═══════════════════╪══════════════════╪══════════════════╡\n",
            "│ Training    │ @stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is │               287 │              140 │              147 │\n",
            "├─────────────┼──────────────────────────────────────────────────────────────────┼───────────────────┼──────────────────┼──────────────────┤\n",
            "│ Testing     │ Ok, first assesment of the #kindle2 ...it fucking rocks!!! Loves │                72 │               42 │               30 │\n",
            "╘═════════════╧══════════════════════════════════════════════════════════════════╧═══════════════════╧══════════════════╧══════════════════╛\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bohIjKBBLxd"
      },
      "source": [
        "2. Use the code from the previous classes to build the following models (15 points):\n",
        "a) SVM using TF-IDF.\n",
        "b) Naive Bayes using TF-IDF.\n",
        "c) Random Forest using TF-IDF.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YchqFylR56u"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wssrByTXlscP",
        "outputId": "b3b077cb-9d75-40c5-e177-de2d0da32490"
      },
      "source": [
        "print(\"Train A SVM\")\n",
        "# c\n",
        "# Create and train a linear support vector classifier (LinearSVC)\n",
        "SVM = LinearSVC(random_state=randomSeed)\n",
        "SVM.fit(X_train, y_train)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train A SVM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=2361, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h8jmkj9lu9a",
        "outputId": "4e216c42-5858-4072-9aea-025ba4136c47"
      },
      "source": [
        "print(\"Train B NB\")\n",
        "# b\n",
        "# Create and train a multinomial naive bayes classifier (MultinomialNB)\n",
        "NB = MultinomialNB()\n",
        "NB.fit(X_train, y_train)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train B NB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm3oCf4ubTS3",
        "outputId": "f8c9dcfd-cd83-4b9b-88e2-76f8ead8f936"
      },
      "source": [
        "print(\"Train C RF\")\n",
        "# c\n",
        "# Create and train a random forest classifier\n",
        "forest = RandomForestClassifier(random_state=randomSeed)\n",
        "forest.fit(X_train, y_train)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train C RF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=2361,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FanKN2Oysm7R"
      },
      "source": [
        "import sklearn.metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# A\n",
        "svm_true = y_test\n",
        "svm_labels = SVM.predict(X_test)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDmC9UqToHe6"
      },
      "source": [
        "# B\n",
        "NB_true = y_test\n",
        "NB_labels = NB.predict(X_test)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HktqJahaoMWg"
      },
      "source": [
        "# C\n",
        "forest_true = y_test\n",
        "forest_labels = forest.predict(X_test)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZc51v_DiddJ"
      },
      "source": [
        "3. Use the code from the LSTM class to build a classifier for negative and positive\n",
        "sentiment tweets. Train the model with the training data split. Once the model is built,\n",
        "test it with the testing data split. Display the classifier report for this evaluation. Answer\n",
        "the following question: What can you say about the performance of this model? (40\n",
        "points)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RspJhYzlF_Wp"
      },
      "source": [
        "# All the imports!\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from numpy import array\n",
        "import re\n",
        "import random\n",
        "\n",
        "tf.random.set_seed(randomSeed)\n",
        "random.seed(randomSeed)\n",
        "np.random.seed(randomSeed)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RmXxGU4V67F"
      },
      "source": [
        "# need to extract words from difficult text\n",
        "getWord = \"[0-9.!:(@)?\\\\-\\*\\#]*([a-zA-Z]+)[0-9.(@:)!?\\\\-\\*\\#]*\"\n",
        "emojis = [\"(:\", \"[:\", \"]:\", \"):\", \"/:\", \"|:\",\":(\", \":[\", \":]\", \":)\", \":/\", \":|\"]\n",
        "compile = re.compile(getWord)\n",
        "urlStarter = \"http\"\n",
        "\n",
        "#convert text to ints\n",
        "intTweets = []\n",
        "for tweet in filteredTweets.text:\n",
        "  split = tweet.split(\" \")\n",
        "  wordInt = []\n",
        "  for raw_word in split:\n",
        "    word = raw_word.lower()\n",
        "    if len(word) > 2 and not word.startswith(urlStarter):\n",
        "        # check if emoji is in word\n",
        "        # if any(emoji in word for emoji in emojis):\n",
        "        for emoji in emojis:\n",
        "          if(emoji in word):\n",
        "            split.append(emoji)\n",
        "    if word not in word_id_pair:\n",
        "      match = compile.match(word)\n",
        "      if match:\n",
        "        grabbedWord = match.group(1)\n",
        "        if grabbedWord in word_id_pair:\n",
        "          wordInt.append(word_id_pair[grabbedWord])\n",
        "        else:\n",
        "          randomValForWord = random.random()\n",
        "          word_id_pair[word] = randomValForWord\n",
        "          wordInt.append(randomValForWord)\n",
        "    else:\n",
        "      wordInt.append(word_id_pair[word])\n",
        "  intTweets.append(wordInt)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhXSpRXtR42z"
      },
      "source": [
        "#need to provide uniform length\n",
        "#since mean is 83 and max is 144 we should raise the average to the mid point (110)\n",
        "review_length = 110\n",
        "\n",
        "# Padding / truncated our reviews\n",
        "intTweets_padded = sequence.pad_sequences(intTweets, maxlen = review_length)\n",
        "\n",
        "# split the tweet using the same randomseed\n",
        "# a 80% training, 20 test\n",
        "tweets_train, tweets_test, y_train, y_test = train_test_split(intTweets_padded, y, train_size=0.8, random_state=randomSeed)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nmO8M4aCKwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fafbf3da-a40b-49e9-9a9e-3a0986ac780c"
      },
      "source": [
        "# We begin by defining the a empty stack. We'll use this for building our \n",
        "# network, later by layer.\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# The Embedding Layer provides a spatial mapping (or Word Embedding) of all the \n",
        "# individual words in our training set. Words close to one another share context \n",
        "# and or meaning. This spatial mapping is learning during the training process.\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = vocab_size, # The size of our vocabulary \n",
        "        output_dim = 32, # Dimensions to which each words shall be mapped\n",
        "        input_length = review_length # Length of input sequences\n",
        "    )\n",
        ")\n",
        "\n",
        "# Dropout layers fight overfitting and forces the model to learn multiple \n",
        "# representations of the same data by randomly disabling neurons in the \n",
        "# learning phase.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# We are using a fast version of LSTM whih is optimised for GPUs. This layer \n",
        "# looks at the sequence of words in the review, along with their word embeddings\n",
        "# and uses both of these to determine to sentiment of a given review.\n",
        "model.add(\n",
        "    tf.keras.layers.LSTM(\n",
        "        units=32 # 32 LSTM units in this layer\n",
        "    )\n",
        ")\n",
        "\n",
        "# Add a second dropout layer with the same aim as the first.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# All LSTM units are connected to a single node in the dense layer. A sigmoid \n",
        "# activation function determines the output from this node - a value \n",
        "# between 0 and 1. Closer to 0 indicates a negative review. Closer to 1 \n",
        "# indicates a positive review.\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1, # Single unit\n",
        "        activation='sigmoid' # Sigmoid activation function (output from 0 to 1)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
        "    metrics=['accuracy']) # reporting metric\n",
        "\n",
        "# Display a summary of the models structure\n",
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 110, 32)           320000    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 110, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 328,353\n",
            "Trainable params: 328,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEN1vV4nG1V3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13eb3527-6540-44fa-f189-f2bba99ad471"
      },
      "source": [
        "# Train the LSTM on the training data\n",
        "history = model.fit(\n",
        "\n",
        "    # Training data : features (review) and classes (positive or negative)\n",
        "    tweets_train, y_train,\n",
        "                    \n",
        "    # Number of samples to work through before updating the \n",
        "    # internal model parameters via back propagation. The \n",
        "    # higher the batch, the more memory you need.\n",
        "    batch_size=128, \n",
        "\n",
        "    # An epoch is an iteration over the entire training data.\n",
        "    epochs=3, \n",
        "    \n",
        "    # The model will set apart his fraction of the training \n",
        "    # data, will not train on it, and will evaluate the loss\n",
        "    # and any model metrics on this data at the end of \n",
        "    # each epoch.\n",
        "    validation_split=0.2,\n",
        "    \n",
        "    verbose=1\n",
        ") "
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2/2 [==============================] - 3s 536ms/step - loss: 0.6938 - accuracy: 0.4399 - val_loss: 0.6931 - val_accuracy: 0.4138\n",
            "Epoch 2/3\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6922 - accuracy: 0.5630 - val_loss: 0.6929 - val_accuracy: 0.4655\n",
            "Epoch 3/3\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6909 - accuracy: 0.5471 - val_loss: 0.6928 - val_accuracy: 0.4655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPnfxwbnITqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ea967b-dd71-409c-ce6f-7e68d727710b"
      },
      "source": [
        "# Get Model Predictions for test data\n",
        "from sklearn.metrics import classification_report\n",
        "predicted_classes = model.predict_classes(tweets_test)\n",
        "classRep = (classification_report(y_test, predicted_classes, target_names=class_names))\n",
        "print(classRep)\n",
        "reportArray = (classRep.split())\n",
        "precision = (float(reportArray[19])*100.0)\n",
        "recall = (float(reportArray[20])*100.0)\n",
        "fOne = (float(reportArray[21])*100.0)\n",
        "lsmt_scores = [\"LSMT\", precision, recall, fOne]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.42      1.00      0.59        30\n",
            "    Positive       0.00      0.00      0.00        42\n",
            "\n",
            "    accuracy                           0.42        72\n",
            "   macro avg       0.21      0.50      0.29        72\n",
            "weighted avg       0.17      0.42      0.25        72\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KUKsx3MYWzH"
      },
      "source": [
        "**ANSWER:**\n",
        "\n",
        "The model did not perform well at all. My assumption is that the corpus/tweets were not tokenized well enough, and there was too much noise in the data to calculate an accurate assumption on what the tweet was."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8do6SKwCjwt"
      },
      "source": [
        "4. Compare all models together in terms of Precision, Recall and F1 score. Put all of\n",
        "these numbers in a nicely formatted dataframe. Answer the following questions: Which\n",
        "model performs the best? Why do you think this is? What do you think you can do to\n",
        "improve performance? (30 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzW0OsWWstWP"
      },
      "source": [
        "**ANSWER**\n",
        "\n",
        "The model perferfomed fairly wild based on Negative and Positive. Negative and Postive scored a 100% for recall and precision respectively but were at 50% or lower for precison and recall respectively. The F1-score was not good either at 68% and 50%. \n",
        "The averages were more consistent but still not as good as expected, precision was over 75%, recall hovered around 60-70% and f1-score was about 60%. I do not think the model performed well but I believe that is directly associated to the quality of the data, much of the words were mispelled, filled with slang, and required strong context. A better parser could have been used to filter the text into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btW4JEtoVeEH"
      },
      "source": [
        "def scores(name, testData, labels):\n",
        "  return [name, sklearn.metrics.precision_score(testData, labels)*100.0, sklearn.metrics.recall_score(testData, labels)*100.0, sklearn.metrics.f1_score(labels, testData, average='macro')*100.0]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADv1qDJWFiZe"
      },
      "source": [
        "# forest scores\n",
        "forest_scores = scores(\"Forest\", forest_true, forest_labels)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CFONFVyGyuC"
      },
      "source": [
        "#naive baiez scores\n",
        "nb_scores = scores(\"NB\", NB_true, NB_labels)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0adWO7h0G0e6"
      },
      "source": [
        "# svm scores\n",
        "svm_scores = scores(\"SVM\", svm_true, svm_labels)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBiB9vw4Oafa",
        "outputId": "704589ae-5349-4365-fcc3-84c1e4aa9621"
      },
      "source": [
        "data = [svm_scores, nb_scores, forest_scores, lsmt_scores]\n",
        "columns = [\"Name\", \"Precision\", \"Recall\", \"F1 Measure\"]\n",
        "scores = pd.DataFrame(data=data,columns=columns)\n",
        "print(\"Scores\")\n",
        "print(tabulate(scores, headers='keys', tablefmt='fancy_grid'))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores\n",
            "╒════╤════════╤═════════════╤══════════╤══════════════╕\n",
            "│    │ Name   │   Precision │   Recall │   F1 Measure │\n",
            "╞════╪════════╪═════════════╪══════════╪══════════════╡\n",
            "│  0 │ SVM    │     80.5556 │  69.0476 │      72.028  │\n",
            "├────┼────────┼─────────────┼──────────┼──────────────┤\n",
            "│  1 │ NB     │     85.7143 │  71.4286 │      76.2745 │\n",
            "├────┼────────┼─────────────┼──────────┼──────────────┤\n",
            "│  2 │ Forest │     79.4118 │  64.2857 │      69.3498 │\n",
            "├────┼────────┼─────────────┼──────────┼──────────────┤\n",
            "│  3 │ LSMT   │     21      │  50      │      29      │\n",
            "╘════╧════════╧═════════════╧══════════╧══════════════╛\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa0aoUTSwvI-"
      },
      "source": [
        "**ANSWER**:\n",
        "\n",
        "Naive Bayes performed the best, with SVM closely behind I belive that is because the dataset provided was fairly small (under 400 items) and both of these algorithms work well with small sets. I believe Naive performed the best because tweets generally do not have a wide vocabularly and similar words are used repetitively which works in Naive Bayes favor. \n",
        "What can be done to improve the scores is increase the amount of tweets, the variety of tweets, and to better tokenize the tweets to feed the algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g__XAgdFvdW"
      },
      "source": [
        "5. Add to the comparison of #4 a the manually calculated precision, recall and F1 score\n",
        "using VADER and their suggested defaults to categorize the test split tweets in positive\n",
        "or negative. Answer the following questions: Is this approach as good as the previous\n",
        "ones? Why do you think this is? (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jfzjgbsFzLY",
        "outputId": "adfea27f-00b4-4d7e-a99c-5613f346ad4d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')  "
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhcG4UFtdrYD"
      },
      "source": [
        "def getPrecision(true_p, false_p):\n",
        "  denom = (true_p + false_p) * 1.0\n",
        "  return (true_p/denom) * 100\n",
        "\n",
        "def getRecall(true_p, false_n):\n",
        "  denom = (true_p + false_n) * 1.0\n",
        "  return (true_p/denom) * 100\n",
        "\n",
        "def getfOne(true_p, false_p, false_n):\n",
        "  prec = getPrecision(true_p, false_p)\n",
        "  recall = getRecall(true_p, false_n)\n",
        "  num = 2.0 * prec * recall\n",
        "  denom = (prec + recall)\n",
        "  return (num/denom)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IhWoPRIXS33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c1a68d-a619-4f9b-9eb8-58e7b1189156"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
        "\n",
        "sia = SIA()\n",
        "\n",
        "true_positive = 0\n",
        "true_negative = 0\n",
        "false_positive = 0\n",
        "false_negative = 0\n",
        "print(\"Test Tweets\")\n",
        "for index, row in filteredTweets.iterrows():\n",
        "  className = class_names[row.polarity]\n",
        "  tweet = (row.text)\n",
        "  score = sia.polarity_scores(tweet)\n",
        "  compound = float(score['compound'])\n",
        "  neutral = float(score['neu'])\n",
        "  negative = float(score['neg'])\n",
        "  positive = float(score['pos'])\n",
        "\n",
        "  if index in training_indexes:   \n",
        "    if negative == positive:\n",
        "      split = tweet.split()\n",
        "    if className == \"Positive\":\n",
        "      if positive > negative:\n",
        "        true_positive += 1\n",
        "      else:\n",
        "        false_negative += 1\n",
        "    else:\n",
        "      if negative > positive:\n",
        "        true_negative += 1\n",
        "      else:\n",
        "        false_positive += 1\n",
        "  if index in testing_indexes:\n",
        "    print(\"Tweet:\",tweet)\n",
        "    print(\"Actual:\",className)\n",
        "    if positive > negative:\n",
        "      print(\"Predicted: Positive\")\n",
        "    elif positive < negative:\n",
        "      print(\"Predicted: Negative\")\n",
        "    else:\n",
        "      print(\"Predicted: Neutral\")\n",
        "    print()\n",
        "\n",
        "precision = getPrecision(true_positive, false_positive) \n",
        "recall = getRecall(true_positive, false_negative)\n",
        "fOne = getfOne(true_positive, false_positive, false_negative)\n",
        "\n",
        "\n",
        "print(\"SCORES\")\n",
        "vader_scores = [\"VADER\", precision, recall, fOne]\n",
        "data=[vader_scores]\n",
        "print(tabulate(data, headers=columns, tablefmt=\"fancy_grid\"))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Tweets\n",
            "Tweet: Ok, first assesment of the #kindle2 ...it fucking rocks!!!\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Loves twitter\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: how can you not love Obama? he makes jokes about himself.\n",
            "Actual: Positive\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: House Correspondents dinner was last night whoopi, barbara &amp; sherri went, Obama got a standing ovation\n",
            "Actual: Positive\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: Watchin Espn..Jus seen this new Nike Commerical with a Puppet Lebron..sh*t was hilarious...LMAO!!!\n",
            "Actual: Positive\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: #lebron best athlete of our generation, if not all time (basketball related) I don't want to get into inter-sport debates about   __1/2\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: @ludajuice Lebron is a Beast, but I'm still cheering 4 the A..til the end.\n",
            "Actual: Negative\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: @Pmillzz lebron IS THE BOSS\n",
            "Actual: Positive\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: good news, just had a call from the Visa office, saying everything is fine.....what a relief! I am sick of scams out there! Stealing!\n",
            "Actual: Positive\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: In montreal for a long weekend of R&amp;R. Much needed.\n",
            "Actual: Positive\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: [#MLUC09] Customer Innovation Award Winner: Booz Allen Hamilton -- http://ping.fm/c2hPP\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: @phyreman9 Google is always a good place to look. Should've mentioned I worked on the Mustang w/ my Dad, @KimbleT.\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: RT @jessverr I love the nerdy Stanford human biology videos - makes me miss school. http://bit.ly/13t7NR\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: I'm listening to \"P.Y.T\" by Danny Gokey &lt;3 &lt;3 &lt;3 Aww, he's so amazing. I &lt;3 him so much :)\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: cant sleep... my tooth is aching.\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: Hello Twitter API ;)\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: @morind45 Because the twitter api is slow and most client's aren't good.\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: just changed my default pic to a Nike basketball cause bball is awesome!!!!!\n",
            "Actual: Positive\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: By the way, I'm totally inspired by this freaky Nike commercial: http://snurl.com/icgj9\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Damn you North Korea. http://bit.ly/KtMeQ\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: Can we just go ahead and blow North Korea off the map already?\n",
            "Actual: Negative\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: Why the hell is Pelosi in freakin China? and on whose dime?\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: Cheney and Bush are the real culprits - http://fwix.com/article/939496\n",
            "Actual: Negative\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: i srsly hate the stupid twitter API timeout thing, soooo annoying!!!!! :(\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: @psychemedia I really liked @kswedberg's \"Learning jQuery\" book. http://bit.ly/pg0lT is worth a look too\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Goodby Silverstein agency new site! http://www.goodbysilverstein.com/ Great!\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Ok so lots of buzz from IO2009 but how lucky are they - a Free G2!! http://is.gd/Hyzl\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: just got a free G2 android at google i/o!!!\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Guess I'll be retiring my G1 and start using my developer G2 woot #googleio\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Judd Apatow creates fake sitcom on NBC.com to market his new movie... viral marketing at its best. http://is.gd/K0yK\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: VIRAL MARKETING FAIL. This Acia Pills brand oughta get shut down for hacking into people's messenger's.  i get 5-6 msgs in a day! Arrrgh!\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: NOOOOOOO my DVR just died and I was only half way through the EA presser. Hate you Time Warner\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: Time warner is the devil. Worst possible time for the Internet to go out.\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: My wrist still hurts. I have to get it looked at. I HATE the dr/dentist/scary places. :( Time to watch Eagle eye. If you want to join, txt!\n",
            "Actual: Positive\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: THE DENTIST LIED! \" U WON'T FEEL ANY DISCOMORT! PROB WON'T EVEN NEED PAIN PILLS\" MAN U TWIPPIN THIS SHIT HURT!! HOW MANY PILLS CAN I TAKE!!\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: The safeway bathroom still smells like ass!\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: At safeway on elkhorn, they move like they're dead!\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: i love Dwight Howard's vitamin water commercial... now i wish he was with NIKE and not adidas. lol.\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Naive Bayes using EM for Text Classification. Really Frustrating...\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: We went to Stanford University today. Got a tour. Made me want to go back to college. It's also decided all of our kids will go there.\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: @Mbjthegreat i really dont want AT&amp;T phone service..they suck when it comes to having a signal\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: pissed about at&amp;t's mid-contract upgrade price for the iPhone (it's $200 more) I'm not going to pay $499 for something I thought was $299\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: Safari 4 is fast :) Even on my shitty AT&amp;T tethering.\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: Obama is quite a good comedian! check out his dinner speech on CNN :) very funny jokes.\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Reading  \"Bill Clinton Fail - Obama Win?\" http://tinyurl.com/pcyxj7\n",
            "Actual: Positive\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: Obama More Popular Than U.S. Among Arabs: Survey: President Barack Obama's popularity in leading Arab countries .. http://tinyurl.com/prlvqu\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Kobe is the best in the world not lebron .\n",
            "Actual: Negative\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Stanford Charity Fashion Show a top draw http://cli.gs/NeNuAH\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Malcolm Gladwell is a genius at tricking people into not realizing he's a fucking idiot\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: RT @clashmore: http://bit.ly/SOYv7  Great article by Malcolm Gladwell.\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: I seriously underestimated Malcolm Gladwell.  I want to meet this dude.\n",
            "Actual: Positive\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: i hate comcast right now. everything is down cable internet &amp; phone....ughh what am i to do\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: Just got my new toy. Canon 50D. Love love love it!\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: LAKERS tonight let's go!!!!\n",
            "Actual: Positive\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: Colin Powell rocked yesterday on CBS. Cheney needs to shut the hell up and go home.Powell is a man of Honor and served our country proudly\n",
            "Actual: Negative\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Absolutely hilarious!!! from @mashable:  http://bit.ly/bccWt\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: @Orli the G2 is amazing btw, a HUGE improvement over the G1\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: @googleio http://twitpic.com/62shi - Yay! Happy place! Place place!  I love Google!\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Night At The Museum 2? Pretty furkin good.\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: just watched night at the museum 2! so stinkin cute!\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: #RantsAndRaves The worst thing about GM (concord / pleasant hill / martinez): is the fucking UAW. ..   http://buzzup.com/4ueb\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: Cox or Time Warner?  Cox is cheaper and gets a B on dslreports.  TW is more expensive and gets a C.\n",
            "Actual: Negative\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: RT @sportsguy33: New Time Warner slogan: \"Time Warner, where we make you long for the days before cable.\"\n",
            "Actual: Negative\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: I know. How sad is that?  RT @caseymercier: 1st day of hurricane season. That's less scarey than govt taking over GM.\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: HATE safeway select green tea icecream! bought two cartons, what a waste of money.  &gt;_&lt;\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: Nike rocks. I'm super grateful for what I've done with them :) &amp; the European Division of NIKE is BEYOND! @whitSTYLES @muchasmuertes\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: @evelynbyrne have you tried Nike  ? V. addictive.\n",
            "Actual: Positive\n",
            "Predicted: Neutral\n",
            "\n",
            "Tweet: argghhhh why won't  my jquery appear in safari bad safari !!!\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "\n",
            "Tweet: I love my Kindle2. No more stacks of books to trip over on the way to the loo.\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: dearest @google, you rich bastards! the VISA card you sent me doesn't work. why screw a little guy like me?\n",
            "Actual: Negative\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: My dad was in NY for a day, we ate at MESA grill last night and met Bobby Flay. So much fun, except I completely lost my voice today.\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "\n",
            "Tweet: Monday already. Iran may implode. Kitchen is a disaster. @annagoss seems happy. @sebulous had a nice weekend and @goldpanda is great. whoop.\n",
            "Actual: Negative\n",
            "Predicted: Positive\n",
            "\n",
            "SCORES\n",
            "╒════════╤═════════════╤══════════╤══════════════╕\n",
            "│ Name   │   Precision │   Recall │   F1 Measure │\n",
            "╞════════╪═════════════╪══════════╪══════════════╡\n",
            "│ VADER  │     67.6301 │  83.5714 │      74.7604 │\n",
            "╘════════╧═════════════╧══════════╧══════════════╛\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcV0rJUE_DJI"
      },
      "source": [
        "**ANSWER:**\n",
        "\n",
        "This approach is as good as the others because the lexicon takes into consideration the context of tweets in the corpus used. So it considers items like text emojis when calculating the score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WDSt5aO2HGW"
      },
      "source": [
        "Bonus (30 points): Try the following things to improve the LSTM model:\n",
        "1) Use 90% training data, 10% testing\n",
        "2) Remove stopwords from the tweets.\n",
        "3) Remove all user mentions for the tweets (@something)\n",
        "Compare all three new models in terms of their precision, recall and F1 score. Answer the\n",
        "following questions: Did this change the results in any way? Why do you think so?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SJWmlnInbcD"
      },
      "source": [
        "Split Text 90/10 Training/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oBOR_34oUv7"
      },
      "source": [
        "#imports\n",
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "import random\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE5hjKJtpmL5"
      },
      "source": [
        "#need to provide uniform length\n",
        "#since mean is 83 and max is 144 we should raise the average to the mid point (110)\n",
        "review_length = 110\n",
        "\n",
        "intTweets_padded = sequence.pad_sequences(intTweets, maxlen = review_length)\n",
        "\n",
        "# split the tweet using the same randomseed\n",
        "#a 90% training, 10 test\n",
        "a_tweets_train, a_tweets_test, a_y_train, a_y_test = train_test_split(intTweets_padded, y, train_size=0.9, random_state=randomSeed)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61Kk7DGPDxVs",
        "outputId": "9538f13a-b58d-4387-9ed7-e21b6d60e99f"
      },
      "source": [
        "# Train the LSTM on the training data\n",
        "history = model.fit(\n",
        "\n",
        "    # Training data : features (review) and classes (positive or negative)\n",
        "    a_tweets_train, a_y_train,\n",
        "                    \n",
        "    # Number of samples to work through before updating the \n",
        "    # internal model parameters via back propagation. The \n",
        "    # higher the batch, the more memory you need.\n",
        "    batch_size=128, \n",
        "\n",
        "    # An epoch is an iteration over the entire training data.\n",
        "    epochs=3, \n",
        "    \n",
        "    # The model will set apart his fraction of the training \n",
        "    # data, will not train on it, and will evaluate the loss\n",
        "    # and any model metrics on this data at the end of \n",
        "    # each epoch.\n",
        "    validation_split=0.2,\n",
        "    \n",
        "    verbose=1\n",
        ") "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.6893 - accuracy: 0.5620 - val_loss: 0.6932 - val_accuracy: 0.4462\n",
            "Epoch 2/3\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6879 - accuracy: 0.5271 - val_loss: 0.6928 - val_accuracy: 0.4462\n",
            "Epoch 3/3\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6851 - accuracy: 0.5775 - val_loss: 0.6919 - val_accuracy: 0.4462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnozcHg9EHNT",
        "outputId": "0049e1e0-ed54-4cd2-e685-d3b81b5c38f7"
      },
      "source": [
        "# Get Model Predictions for test data\n",
        "predicted_classes = model.predict_classes(a_tweets_test)\n",
        "classRep = (classification_report(a_y_test, predicted_classes, target_names=class_names))\n",
        "reportArray = (classRep.split())\n",
        "precision = (float(reportArray[19])*100.0)\n",
        "recall = (float(reportArray[20])*100.0)\n",
        "fOne = (float(reportArray[21])*100.0)\n",
        "nine_one_split = [\"90/10 Split\", precision, recall, fOne]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHumysHgmtOI"
      },
      "source": [
        "Remove StopWords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T33uyO0EgCay",
        "outputId": "78116a62-638c-4bf8-d27c-1547fe6b5661"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "#get stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eypt3I_0ieIZ"
      },
      "source": [
        "random.seed(randomSeed)\n",
        "# need to extract words from difficult text\n",
        "getWord = \"[0-9.!:(@)?\\\\-\\*\\#]*([a-zA-Z]+)[0-9.(@:)!?\\\\-\\*\\#]*\"\n",
        "emojis = [\"(:\", \"[:\", \"]:\", \"):\", \"/:\", \"|:\",\":(\", \":[\", \":]\", \":)\", \":/\", \":|\"]\n",
        "compile = re.compile(getWord)\n",
        "urlStarter = \"http\"\n",
        "#convert text to ints\n",
        "b_intTweets = []\n",
        "for tweet in filteredTweets.text:\n",
        "  split = tweet.split(\" \")\n",
        "  wordInt = []\n",
        "  for raw_word in split:\n",
        "    word = raw_word.lower()\n",
        "    if word not in stop_words:\n",
        "      if len(word) > 2 and not word.startswith(urlStarter):\n",
        "        # check if emoji is in word\n",
        "        # if any(emoji in word for emoji in emojis):\n",
        "        for emoji in emojis:\n",
        "          if(emoji in word):\n",
        "            split.append(emoji)\n",
        "      if word not in word_id_pair:\n",
        "        match = compile.match(word)\n",
        "        if match:\n",
        "          grabbedWord = match.group(1)\n",
        "          if grabbedWord in word_id_pair:\n",
        "            wordInt.append(word_id_pair[grabbedWord])\n",
        "          else:\n",
        "            randomValForWord = random.random()\n",
        "            word_id_pair[word] = randomValForWord\n",
        "            wordInt.append(randomValForWord)\n",
        "      else:\n",
        "        wordInt.append(word_id_pair[word])\n",
        "  b_intTweets.append(wordInt)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnZdo_yd8yv0",
        "outputId": "b302e015-1b9a-4465-e3ad-0db01fa6d1f9"
      },
      "source": [
        "# Review lengths across test and training whole datasets\n",
        "print(\"Maximum review length: {}\".format(len(max((b_intTweets), key=len))))\n",
        "print(\"Minimum review length: {}\".format(len(min((b_intTweets), key=len))))\n",
        "result = [len(x) for x in b_intTweets]\n",
        "print(\"Mean review length: {}\".format(np.mean(result)))\n",
        "\n",
        "#need to provide uniform length\n",
        "#since mean is 9 and max is 20 we should raise the average to the mid point (14)\n",
        "review_length = 14\n",
        "\n",
        "# Padding / truncated our reviews\n",
        "b_intTweets_padded = sequence.pad_sequences(b_intTweets, maxlen = review_length)\n",
        "\n",
        "# split the tweet using the same randomseed\n",
        "# a 80% training, 20 test\n",
        "b_tweets_train, b_tweets_test, b_y_train, b_y_test = train_test_split(b_intTweets_padded, y, train_size=0.8, random_state=randomSeed)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum review length: 20\n",
            "Minimum review length: 2\n",
            "Mean review length: 9.002785515320335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ9WGkinf6p9",
        "outputId": "7874024b-11c6-4685-b3c1-466c91992214"
      },
      "source": [
        "# Train the LSTM on the training data\n",
        "history = model.fit(\n",
        "\n",
        "    # Training data : features (review) and classes (positive or negative)\n",
        "    b_tweets_train, b_y_train,\n",
        "                    \n",
        "    # Number of samples to work through before updating the \n",
        "    # internal model parameters via back propagation. The \n",
        "    # higher the batch, the more memory you need.\n",
        "    batch_size=128, \n",
        "\n",
        "    # An epoch is an iteration over the entire training data.\n",
        "    epochs=3, \n",
        "    \n",
        "    # The model will set apart his fraction of the training \n",
        "    # data, will not train on it, and will evaluate the loss\n",
        "    # and any model metrics on this data at the end of \n",
        "    # each epoch.\n",
        "    validation_split=0.2,\n",
        "    \n",
        "    verbose=1\n",
        ") "
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2/2 [==============================] - 2s 531ms/step - loss: 0.6812 - accuracy: 0.7031 - val_loss: 0.6908 - val_accuracy: 0.4828\n",
            "Epoch 2/3\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6804 - accuracy: 0.7380 - val_loss: 0.6902 - val_accuracy: 0.5172\n",
            "Epoch 3/3\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6779 - accuracy: 0.8166 - val_loss: 0.6896 - val_accuracy: 0.5345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7UbnM2DkVjC",
        "outputId": "e772e176-cc66-4c58-9f15-8a8717b5fc6b"
      },
      "source": [
        "# Get Model Predictions for test data\n",
        "from sklearn.metrics import classification_report\n",
        "predicted_classes = model.predict_classes(b_tweets_test)\n",
        "classRep = (classification_report(b_y_test, predicted_classes, target_names=class_names))\n",
        "reportArray = (classRep.split())\n",
        "precision = (float(reportArray[19])*100.0)\n",
        "recall = (float(reportArray[20])*100.0)\n",
        "fOne = (float(reportArray[21])*100.0)\n",
        "no_stop_words_scores = [\"No Stop Words\", precision, recall, fOne]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXB_t8v8n2Bc"
      },
      "source": [
        "Remove @words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjmaepVOjEAP"
      },
      "source": [
        "random.seed(randomSeed)\n",
        "# need to extract words from difficult text\n",
        "getWord = \"[0-9.!:(@)?\\\\-\\*\\#]*([a-zA-Z]+)[0-9.(@:)!?\\\\-\\*\\#]*\"\n",
        "emojis = [\"(:\", \"[:\", \"]:\", \"):\", \"/:\", \"|:\",\":(\", \":[\", \":]\", \":)\", \":/\", \":|\"]\n",
        "compile = re.compile(getWord)\n",
        "urlStarter = \"http\"\n",
        "#convert text to ints\n",
        "c_intTweets = []\n",
        "for tweet in filteredTweets.text:\n",
        "  split = tweet.split(\" \")\n",
        "  wordInt = []\n",
        "  for raw_word in split:\n",
        "    if not raw_word.startswith(\"@\"):\n",
        "      word = raw_word.lower()\n",
        "      if len(word) > 2 and not word.startswith(urlStarter):\n",
        "          # check if emoji is in word\n",
        "          # if any(emoji in word for emoji in emojis):\n",
        "          for emoji in emojis:\n",
        "            if(emoji in word):\n",
        "              split.append(emoji)\n",
        "      if word not in word_id_pair:\n",
        "        match = compile.match(word)\n",
        "        if match:\n",
        "          grabbedWord = match.group(1)\n",
        "          if grabbedWord in word_id_pair:\n",
        "            wordInt.append(word_id_pair[grabbedWord])\n",
        "          else:\n",
        "            randomValForWord = random.random()\n",
        "            word_id_pair[word] = randomValForWord\n",
        "            wordInt.append(randomValForWord)\n",
        "      else:\n",
        "        wordInt.append(word_id_pair[word])\n",
        "  c_intTweets.append(wordInt)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtxFxedNjpZk",
        "outputId": "a10ab5c3-f6f5-4377-dac7-41166e867821"
      },
      "source": [
        "# Review lengths across test and training whole datasets\n",
        "print(\"Maximum review length: {}\".format(len(max((c_intTweets), key=len))))\n",
        "print(\"Minimum review length: {}\".format(len(min((c_intTweets), key=len))))\n",
        "result = [len(x) for x in c_intTweets]\n",
        "print(\"Mean review length: {}\".format(np.mean(result)))\n",
        "\n",
        "#need to provide uniform length\n",
        "#since mean is 13 and max is 30 we should raise the average to the mid point (21)\n",
        "review_length = 21\n",
        "\n",
        "# Padding / truncated our reviews\n",
        "c_intTweets_padded = sequence.pad_sequences(c_intTweets, maxlen = review_length)\n",
        "\n",
        "# split the tweet using the same randomseed\n",
        "# a 80% training, 20 test\n",
        "c_tweets_train, c_tweets_test, c_y_train, c_y_test = train_test_split(c_intTweets_padded, y, train_size=0.8, random_state=randomSeed)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum review length: 30\n",
            "Minimum review length: 2\n",
            "Mean review length: 13.743732590529248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0f-5aQ5mctI",
        "outputId": "7c1a91f8-2f2b-4b8a-dc76-f2cf601162b8"
      },
      "source": [
        "# Train the LSTM on the training data\n",
        "history = model.fit(\n",
        "\n",
        "    # Training data : features (review) and classes (positive or negative)\n",
        "    c_tweets_train, c_y_train,\n",
        "                    \n",
        "    # Number of samples to work through before updating the \n",
        "    # internal model parameters via back propagation. The \n",
        "    # higher the batch, the more memory you need.\n",
        "    batch_size=128, \n",
        "\n",
        "    # An epoch is an iteration over the entire training data.\n",
        "    epochs=3, \n",
        "    \n",
        "    # The model will set apart his fraction of the training \n",
        "    # data, will not train on it, and will evaluate the loss\n",
        "    # and any model metrics on this data at the end of \n",
        "    # each epoch.\n",
        "    validation_split=0.2,\n",
        "    \n",
        "    verbose=1\n",
        ") "
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2/2 [==============================] - 2s 539ms/step - loss: 0.6748 - accuracy: 0.8515 - val_loss: 0.6885 - val_accuracy: 0.5690\n",
            "Epoch 2/3\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6729 - accuracy: 0.8908 - val_loss: 0.6875 - val_accuracy: 0.5690\n",
            "Epoch 3/3\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6693 - accuracy: 0.8996 - val_loss: 0.6864 - val_accuracy: 0.5862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hlvnn1pkaXj",
        "outputId": "77d934a9-5882-485d-9fb4-eb5963ceb277"
      },
      "source": [
        "# Get Model Predictions for test data\n",
        "from sklearn.metrics import classification_report\n",
        "predicted_classes = model.predict_classes(c_tweets_test)\n",
        "classRep = (classification_report(c_y_test, predicted_classes, target_names=class_names))\n",
        "reportArray = (classRep.split())\n",
        "precision = (float(reportArray[19])*100.0)\n",
        "recall = (float(reportArray[20])*100.0)\n",
        "fOne = (float(reportArray[21])*100.0)\n",
        "no_at_text_scores = [\"No @ text\", precision, recall, fOne]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7ovfwool-aw",
        "outputId": "c66cb64d-872b-479a-d266-441a6b59f397"
      },
      "source": [
        "data = [nine_one_split, no_stop_words_scores, no_at_text_scores]\n",
        "columns = [\"Name\", \"Precision\", \"Recall\", \"F1 Measure\"]\n",
        "scores = pd.DataFrame(data=data,columns=columns)\n",
        "print(\"Scores\")\n",
        "print(tabulate(scores, headers='keys', tablefmt='fancy_grid'))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores\n",
            "╒════╤═══════════════╤═════════════╤══════════╤══════════════╕\n",
            "│    │ Name          │   Precision │   Recall │   F1 Measure │\n",
            "╞════╪═══════════════╪═════════════╪══════════╪══════════════╡\n",
            "│  0 │ 90/10 Split   │          21 │       50 │           29 │\n",
            "├────┼───────────────┼─────────────┼──────────┼──────────────┤\n",
            "│  1 │ No Stop Words │          75 │       63 │           54 │\n",
            "├────┼───────────────┼─────────────┼──────────┼──────────────┤\n",
            "│  2 │ No @ text     │          76 │       67 │           59 │\n",
            "╘════╧═══════════════╧═════════════╧══════════╧══════════════╛\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDh8FH5gRMuu"
      },
      "source": [
        "**ANSWER:**\n",
        "\n",
        "\n",
        "\n",
        "The data has been mostly positively. For the first, splitting the data as 90/10 did not impact the scores much and that could do with pooly tokenized text and noise. For the second and third, the scores drastically and both have to do with removing noise from the tweets, removing the stop words or @texts removed noise that was negatively impacting the lsmt algorithm."
      ]
    }
  ]
}