{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exam 2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZMvJ1wt2jnRgehVSLE5i+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nogbazghi/CSC8980/blob/main/Exam_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOF-J3IeOy60"
      },
      "source": [
        "Nahom Ogbazghi\n",
        "002052292"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBRG97rHSFG0"
      },
      "source": [
        "Question 1) (20 points) Write a function that takes a List of five words: [‘apple’, ‘house’, ‘pear’,\n",
        "‘dog’, ‘doctor’] and returns a list of lists with each element being a word and a list of the top five\n",
        "most similar words. For this task you have to use the most suitable method of the ones we have\n",
        "seen in class to determine the most similar words to the original input list. You can use a\n",
        "pre-trained resource if you think is appropriate. After calling your function, print the most similar\n",
        "words to the screen. Are these ‘similar’ words actually similar? If not, why not? What do you\n",
        "think can be improved and how - talk about it, do not necessarily implement it?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbzSJZueQwXi"
      },
      "source": [
        "randomSeed = 12345"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdymnHzW4haF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25347634-9c52-40b3-b7dc-00526ba01763"
      },
      "source": [
        "!gdown --id 0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:11, 147MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1uL2NfV49Vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f9ac072-44fd-4e0f-c8de-adf29ba2321a"
      },
      "source": [
        "!gunzip /content/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: /content/GoogleNews-vectors-negative300.bin already exists; do you wish to overwrite (y or n)? ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czS1fIzf5MNA"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "filename = '/content/GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQeb1W2lMXam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7338c2ee-8ebf-4777-d7df-6eefa2ae6a71"
      },
      "source": [
        "print(\"Words and there five most similar words\")\n",
        "words = ['apple', 'house', 'pear', 'dog', 'doctor']\n",
        "def mostSimilarWords(wordsList):\n",
        "  allSimilarWords = []\n",
        "  for word in wordsList:\n",
        "    similarWords = []\n",
        "    similarWords = model.most_similar(word)\n",
        "    topFIve = [wordTuple[0] for wordTuple in similarWords[:5]]\n",
        "    allSimilarWords.append([word, topFIve])\n",
        "  return allSimilarWords\n",
        "mostSimilarWords(words)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words and there five most similar words\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['apple', ['apples', 'pear', 'fruit', 'berry', 'pears']],\n",
              " ['house', ['houses', 'bungalow', 'apartment', 'bedroom', 'townhouse']],\n",
              " ['pear', ['pears', 'apricot', 'apricots', 'nectarine', 'Fuji_apple']],\n",
              " ['dog', ['dogs', 'puppy', 'pit_bull', 'pooch', 'cat']],\n",
              " ['doctor', ['physician', 'doctors', 'gynecologist', 'surgeon', 'dentist']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seJKTCMBa682"
      },
      "source": [
        "**ANSWER:**\n",
        "All in all the majority were similar, but there occasionally were words that could have ben substituted for a more similar word: (condo - instead of bedroom),(another type of dog- instead of cat), and really all words for apple except for apples. Improvements can be made by considering a more unique corpus to search each word through versus a general Google one. A fruit corpus for apple/pears, medical corpus for doctor, etc. This would allow for better contextualized information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-YMueVTbDFb"
      },
      "source": [
        "\n",
        "Question 2) (30 points) Using the Homework 2 dataset, also attached in the Exam 2 files,\n",
        "shakespeares-works_TXT_FolgerShakespeare.zip. Find the document to document similarity\n",
        "using:\n",
        "a) Cosine similarity. And create a 42 x 42 heatmap of these similarities.\n",
        "b) Use Doc2Vec to create document embeddings and find the similarities between the\n",
        "documents. To visualize this, also create a 42 x 42 heatmap for this.\n",
        "c) What are the differences you find between the two methods? Is there anything radically\n",
        "different? Please describe your answer in terms of the heatmap of part a and part b.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eY9jqg6bFdM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5cfee9e-8a17-49f6-da14-9dd763f6bbe8"
      },
      "source": [
        "# !pip install wget\n",
        "# import wget\n",
        "!mkdir -p data\n",
        "!unzip -n -d data /content/shakespeares-works_TXT_FolgerShakespeare.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/shakespeares-works_TXT_FolgerShakespeare.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkVzaFu8tIXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125974c7-ba25-456c-c0c8-346d3c38fedd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kfx1cdFer1b"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import sklearn.metrics\n",
        "import nltk\n",
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "dir = \"/content/data/\"\n",
        "matrix = {}\n",
        "N=42\n",
        "getWord = \"[0-9.!:(@)?\\\\-\\*\\#]*([a-zA-Z]+\\'?[a-z]*)[0-9.(@:)!?\\\\-\\*\\#]*\"\n",
        "compile = re.compile(getWord)\n",
        "allFilenames = []\n",
        "taggedDocs = []\n",
        "shakespearContent = []\n",
        "for filename in os.listdir(dir):\n",
        "  if filename.endswith(\".txt\"):\n",
        "    allFilenames.append(filename)\n",
        "    doctwovecContent = []\n",
        "    wordcount_for_File = {}\n",
        "    content = open(dir+str(filename), 'r').read()\n",
        "    shakespearContent.append(content)\n",
        "    words = content.split()\n",
        "    for raw_word in words:\n",
        "      w = raw_word.lower()\n",
        "      match = compile.match(w)\n",
        "      if match:\n",
        "        grabbedWord = match.group(1)\n",
        "        if grabbedWord not in doctwovecContent:\n",
        "          doctwovecContent.append(grabbedWord)\n",
        "        if grabbedWord in matrix:\n",
        "          grabbedWord_dict = matrix[grabbedWord]\n",
        "          if filename in grabbedWord_dict:\n",
        "            wordCount = grabbedWord_dict[filename]\n",
        "            wordCount+=1\n",
        "            grabbedWord_dict[filename] = wordCount\n",
        "            matrix[grabbedWord] = grabbedWord_dict\n",
        "          else:\n",
        "            grabbedWord_dict[filename] = 1\n",
        "            matrix[grabbedWord] = grabbedWord_dict\n",
        "        else:\n",
        "          matrix[grabbedWord] = {filename: 1}\n",
        "    #doc2vec api recommended passing a taggedDocument object\n",
        "    taggedDoc = TaggedDocument(words=doctwovecContent, tags=[filename])\n",
        "    taggedDocs.append(taggedDoc)\n",
        "\n",
        "# Structure of matrix\n",
        "# {word : {filename : wordCount within file}}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEGDGE1usCmh"
      },
      "source": [
        "def tf(word, doc):\n",
        "  if word in matrix:\n",
        "    files = matrix[word]\n",
        "    if doc in files:\n",
        "      count = files[doc]\n",
        "      return count\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def idf(word):\n",
        "  docCount = len(matrix[word])\n",
        "  # print(docCount)\n",
        "  idf = N/docCount\n",
        "  return idf\n",
        "\n",
        "def tf_idf(word, doc):\n",
        "  tfValue = tf(word, doc)\n",
        "  idfValue = idf(word)\n",
        "  return tfValue * idfValue"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv6qjRiysPyz"
      },
      "source": [
        "all_words = matrix.keys()\n",
        "tfidfsMatrix = {}\n",
        "for word in all_words:\n",
        "  listOfFileCount = matrix[word]\n",
        "  for f in listOfFileCount:\n",
        "    tf_idfCount = tf_idf(word, f)\n",
        "    if f in tfidfsMatrix:\n",
        "      word_tfidf = tfidfsMatrix[f]\n",
        "      word_tfidf[word] = tf_idfCount\n",
        "    else:\n",
        "      word_tfidf = {word: tf_idfCount}\n",
        "      tfidfsMatrix[f] = word_tfidf"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSa72nvNLla3"
      },
      "source": [
        "def denomCS(fileA, fileB):\n",
        "  fileAwks = list(tfidfsMatrix[fileA].values())\n",
        "  fileBwks = list(tfidfsMatrix[fileB].values())\n",
        "  kA = len(fileAwks)\n",
        "  kB = len(fileBwks)\n",
        "  totalA = 0\n",
        "  for tfidfScore in fileAwks:\n",
        "    totalA += math.pow(tfidfScore, 2)\n",
        "  totalB=0\n",
        "  for tfidfScore in fileBwks:\n",
        "    totalB += math.pow(tfidfScore, 2)\n",
        "  left = math.sqrt(totalA)\n",
        "  right = math.sqrt(totalB)\n",
        "  denom = left * right\n",
        "  return denom"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14k8AFaizfHj"
      },
      "source": [
        "tfidfsScoreMatrix = []\n",
        "for keyfile in allFilenames:\n",
        "  scores = []\n",
        "  for secondFile in allFilenames:\n",
        "    keywords = tfidfsMatrix[keyfile]\n",
        "    secondwords = tfidfsMatrix[secondFile]\n",
        "    denom = denomCS(keyfile, secondFile)\n",
        "    num = 0\n",
        "    wordsToUse = []\n",
        "    if len(keywords) < len(secondwords):\n",
        "      wordsToUse = keywords\n",
        "    else:\n",
        "      wordsToUse = secondwords\n",
        "    for word in wordsToUse:\n",
        "      if word in keywords and word in secondwords:\n",
        "        keyVal = keywords[word]\n",
        "        secVal = secondwords[word]\n",
        "        mult = keyVal * secVal\n",
        "        num += mult\n",
        "    score = num/denom\n",
        "    scores.append(score)\n",
        "  tfidfsScoreMatrix.append(scores)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynTEqpr4PS2C",
        "outputId": "f4101288-71b9-4352-87f8-683d1a1e871f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(tfidfsScoreMatrix)\n",
        "# mat = confusion_matrix(tfidfsScoreMatrix, allFilenames)\n",
        "# sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "#             xticklabels=allFilenames, yticklabels=allFilenames)\n",
        "# plt.xlabel('true label')\n",
        "# plt.ylabel('predicted label');"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9999999999999999, 0.03883830101249319, 0.026366467716441393, 0.02833673470500418, 0.062195309806368164, 0.05210219869914298, 0.06520495422556485, 0.028641156821921893, 0.07057722591429658, 0.02412903121161592, 0.02603132188818433, 0.02317543341239399, 0.013170215879546367, 0.09908250079153197, 0.020592088944247612, 0.0209477147254021, 0.033626515059821935, 0.03151665724059068, 0.01596295805813951, 0.06653009920357413, 0.029231806947803876, 0.11077835032100461, 0.031329829128391565, 0.022744979956505824, 0.023542315976830996, 0.017292064995466812, 0.08597239301963992, 0.05914099490369381, 0.07583524141781998, 0.026183580316338533, 0.0242634863433639, 0.03398716865458982, 0.03287429242156608, 0.1416974872252486, 0.019997642422751528, 0.09095400592124175, 0.04403965905185058, 0.027057096929003883, 0.025831064053697617, 0.021416162760757158, 0.07413242719920399, 0.030798225359168065], [0.03883830101249319, 1.0, 0.031773452777253484, 0.03539881766662724, 0.07637670102039307, 0.06543802514629536, 0.08236108374096675, 0.03897387178960437, 0.08859161967669245, 0.029864505793557237, 0.033860245669659485, 0.028543288480901433, 0.01629106240600962, 0.1334451585938837, 0.02692611332871502, 0.02590562576312168, 0.042699856249819326, 0.03936900496682133, 0.01904207185712521, 0.0857309165858833, 0.03866276061552529, 0.14453428687374928, 0.04025439171640523, 0.028293724933270915, 0.02899638112936586, 0.021804143622082016, 0.11011634040346119, 0.07522223499998257, 0.09585794127593901, 0.032827512813637605, 0.029402078536432216, 0.042903144989088794, 0.04032369138045869, 0.1775943691700019, 0.025131172770735587, 0.1143050310931026, 0.05468096949502886, 0.03302611253624556, 0.03201073333492582, 0.02737066012106327, 0.09207140695380242, 0.03894700017324689], [0.026366467716441393, 0.031773452777253484, 0.9999999999999998, 0.02297412582171266, 0.050474775603746524, 0.04226165697172618, 0.052956111278257126, 0.02327441090902029, 0.05669584454665018, 0.019767274497503935, 0.02109736263445001, 0.018832249919977007, 0.010937233081917639, 0.0814601397483959, 0.016605183449205026, 0.017288917759507926, 0.027733951749325716, 0.025545948269171916, 0.016919804000450685, 0.05476995406850829, 0.02395712571765319, 0.09319353638427164, 0.02529114917167498, 0.018628911351292056, 0.019085547433670972, 0.014174702216138882, 0.07005496380633132, 0.04833215415721534, 0.06200195522813515, 0.02140437438049086, 0.01957759611991643, 0.02778796807137358, 0.026465185583688634, 0.11336688587947695, 0.01605827011262845, 0.07342172000729562, 0.03629038293063621, 0.021837751484882532, 0.020849456675243294, 0.01745077549974613, 0.059603163209022904, 0.05869231036722231], [0.02833673470500418, 0.03539881766662724, 0.02297412582171266, 1.0, 0.05635697808559986, 0.046881623225602735, 0.058593141454746, 0.026734918009916307, 0.06303071431272551, 0.02130344520439142, 0.023238710942515308, 0.02055126387407548, 0.011652706060408585, 0.09168506628113177, 0.018170367347852406, 0.018572621186213983, 0.04833484140639631, 0.028171440954443065, 0.01370973831826939, 0.06117911707144513, 0.026671436405810222, 0.10064844098382952, 0.027878349176503874, 0.0200784115370499, 0.02117430710537471, 0.015862265776844603, 0.07709026003419298, 0.05315617664523483, 0.06777967210113768, 0.02527338704994918, 0.020935355380814223, 0.04389903792172852, 0.029687194469120905, 0.12358157884297678, 0.018020714333452547, 0.08209562090730714, 0.039581959240507496, 0.02435410536604381, 0.023108761242218497, 0.018891668580228737, 0.06630458808012411, 0.0274686214759716], [0.062195309806368164, 0.07637670102039307, 0.050474775603746524, 0.05635697808559986, 1.0, 0.10721387920389998, 0.16374738111497564, 0.05610337236700771, 0.14825274499314922, 0.0537822966014859, 0.05398932930872713, 0.04503458467589688, 0.02596844570050576, 0.19814942950221517, 0.03996509937906871, 0.04066193034599369, 0.06633170350069385, 0.0619573257355059, 0.02986095341306451, 0.1449778851380432, 0.05842948755211186, 0.2194720168448274, 0.06178726897286266, 0.04409394766175655, 0.0462999719061893, 0.03439006018192147, 0.17971240387506046, 0.1300972955998942, 0.15289115386430685, 0.051564881321266215, 0.04626064621089999, 0.06672618179566922, 0.06488381730758007, 0.2714875883335937, 0.03983755416304234, 0.18355133864896359, 0.0885600302551314, 0.052512911882649185, 0.05077071001300846, 0.04134463566680154, 0.1919623192050815, 0.0602736578802967], [0.05210219869914298, 0.06543802514629536, 0.04226165697172618, 0.046881623225602735, 0.10721387920389998, 1.0, 0.12732135253838592, 0.04768936214405324, 0.12789447057521944, 0.0388826488074953, 0.04413399112366615, 0.038846152313716735, 0.022272033261934842, 0.1765783148821787, 0.0335053410557337, 0.03406017019750001, 0.05824390876773707, 0.0520584792328089, 0.02514639347282401, 0.13001111419180703, 0.053482930259438434, 0.19361426105921398, 0.05151911984207489, 0.037744663625355244, 0.038948845867599884, 0.029596460434730874, 0.15716161478933283, 0.11343965524207462, 0.13280876832062194, 0.04365861497202805, 0.038764883661334903, 0.056936026539384565, 0.05373488851870604, 0.24581306300391936, 0.033982367271759274, 0.16047706561082134, 0.07278901488018505, 0.04427570171613459, 0.04324356004006511, 0.03631528946982599, 0.13069673448067012, 0.05193286262898654], [0.06520495422556485, 0.08236108374096675, 0.052956111278257126, 0.058593141454746, 0.16374738111497564, 0.12732135253838592, 1.0000000000000002, 0.060141337335675234, 0.1827593458189218, 0.049296993874404726, 0.05515182338994724, 0.04873488534957728, 0.027706190171560383, 0.22348606451697767, 0.0417682665752458, 0.04290388879043968, 0.07409200661789207, 0.06581313221962583, 0.031596539061370645, 0.16358713751026246, 0.06781671670310087, 0.2486154323846075, 0.06444366073907928, 0.05026572480516147, 0.04884306525314736, 0.03742381838521499, 0.34274222884100586, 0.21280308254959304, 0.16999219415603098, 0.055328087841706335, 0.048828356304660966, 0.07147312718162581, 0.06798078144224082, 0.3063699723790095, 0.04253863256828498, 0.20878113284385455, 0.08938872308655964, 0.055518154684955114, 0.06154706235891531, 0.04536337730636131, 0.22020109377402555, 0.06549847728238417], [0.028641156821921893, 0.03897387178960437, 0.02327441090902029, 0.026734918009916307, 0.05610337236700771, 0.04768936214405324, 0.060141337335675234, 1.0, 0.06481036275375077, 0.02163112307735413, 0.02409116837698186, 0.02103912080632169, 0.01194477015885056, 0.09316428673552056, 0.018562365090851934, 0.018858789643957187, 0.03231635430101024, 0.028467980186921114, 0.014017905335899476, 0.06278284919317088, 0.02709273969461833, 0.10425883514212661, 0.028277894294076896, 0.02040965075370146, 0.021280402488773578, 0.01601362831110527, 0.07930194101717586, 0.054449686230190766, 0.06912809135535603, 0.02468758670845267, 0.021666228536092333, 0.14251207616809677, 0.03293644244296265, 0.12992525492722737, 0.018285193998405454, 0.08269895992676911, 0.03957147805210408, 0.02508297376165967, 0.02348642059089202, 0.01985174236779314, 0.06778030355457221, 0.0290406390761364], [0.07057722591429658, 0.08859161967669245, 0.05669584454665018, 0.06303071431272551, 0.14825274499314922, 0.12789447057521944, 0.1827593458189218, 0.06481036275375077, 1.0000000000000002, 0.05264808275319662, 0.05951589733098733, 0.05264663637226341, 0.03006491084185324, 0.24286141884997925, 0.04516043520151698, 0.045985916223097154, 0.07935199736021693, 0.07077751787801828, 0.034159427606676396, 0.16690181056770312, 0.07090867398177844, 0.26506221264178065, 0.0697948700631387, 0.049684253259598396, 0.052643637028275236, 0.047364963977974905, 0.25349697357382506, 0.15360762305819436, 0.2009836466229883, 0.05996258925387346, 0.05290420939429013, 0.07686566865741715, 0.07257110692380826, 0.3399219518647933, 0.046128367850856104, 0.2474744493128145, 0.09508978772785642, 0.060093953108754365, 0.059377918784649264, 0.049207706672333554, 0.21255992219862363, 0.07022013083945233], [0.02412903121161592, 0.029864505793557237, 0.019767274497503935, 0.02130344520439142, 0.0537822966014859, 0.0388826488074953, 0.049296993874404726, 0.02163112307735413, 0.05264808275319662, 1.0, 0.0225156557761382, 0.017776949834363846, 0.010108880471219219, 0.07333989566306161, 0.016057127851864642, 0.016210663501105352, 0.026237855242824064, 0.02442502567684971, 0.014981150409245227, 0.05631381869331305, 0.021314026679401233, 0.08485268075679633, 0.02395719854181694, 0.018010096399173618, 0.017917492671282287, 0.01289403368148154, 0.06536258659590265, 0.04467581811780054, 0.05837600045130576, 0.020028914425320194, 0.019249236508094295, 0.026269348608216985, 0.025203284678920416, 0.10693624266422651, 0.015216810102332274, 0.06947809326702128, 0.035490944670052454, 0.020317447123589592, 0.019670154574229312, 0.01955048955241662, 0.056211954625447015, 0.02399839470862073], [0.02603132188818433, 0.033860245669659485, 0.02109736263445001, 0.023238710942515308, 0.05398932930872713, 0.04413399112366615, 0.05515182338994724, 0.02409116837698186, 0.05951589733098733, 0.0225156557761382, 1.0, 0.019030900719264002, 0.010865619315546497, 0.08548277046762852, 0.01995289908932978, 0.01740398620033366, 0.027997266086614833, 0.026474991678188, 0.01258819922293873, 0.05991126458791599, 0.026386583739141118, 0.09567021027104297, 0.026754631535467064, 0.019017726725339457, 0.01934865840074234, 0.014457859219824907, 0.07252462577928742, 0.050174312694089944, 0.06398943983450861, 0.022596333028729546, 0.019791145534405613, 0.028175171147334456, 0.02782199036658427, 0.11788744107755551, 0.016730016051402778, 0.07635401939163589, 0.03667688777598203, 0.022046896266489265, 0.021248645278679514, 0.019948852872841098, 0.061465435150047654, 0.026047514320094934], [0.02317543341239399, 0.028543288480901433, 0.018832249919977007, 0.02055126387407548, 0.04503458467589688, 0.038846152313716735, 0.04873488534957728, 0.02103912080632169, 0.05264663637226341, 0.017776949834363846, 0.019030900719264002, 1.0000000000000002, 0.009722974752954175, 0.07307382664014252, 0.019431688086647983, 0.015282546004091103, 0.02526963593017252, 0.02863076531926898, 0.011357925835738362, 0.04920808224820099, 0.02187694110043609, 0.08232998134326167, 0.022762592871324535, 0.01664550297993091, 0.0171339183214719, 0.012726490348672388, 0.06446868214763235, 0.04427825976021491, 0.05668215392936427, 0.019438526055163944, 0.02267153005235065, 0.025004763344798977, 0.023640655101441786, 0.10716223139783253, 0.014628367085631665, 0.06676225288088676, 0.03212067264156391, 0.019609366578707717, 0.01904658703585116, 0.01601622170058907, 0.054563930483606846, 0.023010996881306253], [0.013170215879546367, 0.01629106240600962, 0.010937233081917639, 0.011652706060408585, 0.02596844570050576, 0.022272033261934842, 0.027706190171560383, 0.01194477015885056, 0.03006491084185324, 0.010108880471219219, 0.010865619315546497, 0.009722974752954175, 1.0, 0.041609825346630214, 0.008798209812997988, 0.008817312899439614, 0.01408992671537406, 0.013482004125138928, 0.006671732364539766, 0.028715694798853653, 0.01173304063396296, 0.04573138934449901, 0.013108410469762837, 0.00966433892392974, 0.012574916423226215, 0.007180549510112881, 0.03593762538851321, 0.0255037438864717, 0.03263886637469545, 0.011075130158345369, 0.010156524417476461, 0.014355129610674009, 0.022711510541830262, 0.06071613380232968, 0.008342789452796278, 0.038787043699212494, 0.01898153925459111, 0.011152174528567742, 0.01083778677577958, 0.009155032545604012, 0.03165566134506786, 0.012939144353344385], [0.09908250079153197, 0.1334451585938837, 0.0814601397483959, 0.09168506628113177, 0.19814942950221517, 0.1765783148821787, 0.22348606451697767, 0.09316428673552056, 0.24286141884997925, 0.07333989566306161, 0.08548277046762852, 0.07307382664014252, 0.041609825346630214, 1.0, 0.06209689258974723, 0.06402552244041955, 0.11889531395365355, 0.09841911292697111, 0.047885047903829886, 0.22656931267676866, 0.11693406567596455, 0.45773325977749396, 0.09669323375122825, 0.06978311545870493, 0.07660188823298546, 0.05814176328683854, 0.29799578153574735, 0.20333057970011353, 0.2442755713261183, 0.08474061959784529, 0.07497746194398369, 0.11166373224126597, 0.10162780703900248, 0.5033262657327233, 0.06518822342363945, 0.2903250546502607, 0.12899366112500602, 0.08632128831899256, 0.08180910676963772, 0.07102357629123639, 0.24535204074572764, 0.10060995727245398], [0.020592088944247612, 0.02692611332871502, 0.016605183449205026, 0.018170367347852406, 0.03996509937906871, 0.0335053410557337, 0.0417682665752458, 0.018562365090851934, 0.04516043520151698, 0.016057127851864642, 0.01995289908932978, 0.019431688086647983, 0.008798209812997988, 0.06209689258974723, 1.0, 0.013830833554600104, 0.02189566487236139, 0.02218019532373577, 0.010349227821942355, 0.04320722596284147, 0.017822183381387947, 0.07015495702217113, 0.02093859069770804, 0.015207816467740082, 0.015075850635869258, 0.011010663364708928, 0.0546328879912984, 0.03806577379626567, 0.049619155633998845, 0.01715608448657157, 0.018371714269165857, 0.0222899186568757, 0.02154032148397881, 0.09224965531848349, 0.012913197796358836, 0.05949029718312664, 0.029952874262000734, 0.01736245531747586, 0.01700405062644495, 0.014208978254103671, 0.04782083965443127, 0.020162901952240356], [0.0209477147254021, 0.02590562576312168, 0.017288917759507926, 0.018572621186213983, 0.04066193034599369, 0.03406017019750001, 0.04290388879043968, 0.018858789643957187, 0.045985916223097154, 0.016210663501105352, 0.01740398620033366, 0.015282546004091103, 0.008817312899439614, 0.06402552244041955, 0.013830833554600104, 1.0, 0.022379177974295374, 0.021116263203550503, 0.010303044834429639, 0.04467234112478082, 0.018982414748640146, 0.07296549846462534, 0.02114100162418293, 0.015598669212085236, 0.015507920500933504, 0.011266539726728033, 0.05617375913927633, 0.04004800983313107, 0.050449872795180914, 0.01730884961722359, 0.016289876370127323, 0.02283907331294732, 0.022411670117470316, 0.0934295823004606, 0.013059623807704748, 0.06024033891838518, 0.029942332975133792, 0.017536970960836947, 0.01702210987941842, 0.014277646711913686, 0.0485842676903483, 0.020866970424025785], [0.033626515059821935, 0.042699856249819326, 0.027733951749325716, 0.04833484140639631, 0.06633170350069385, 0.05824390876773707, 0.07409200661789207, 0.03231635430101024, 0.07935199736021693, 0.026237855242824064, 0.027997266086614833, 0.02526963593017252, 0.01408992671537406, 0.11889531395365355, 0.02189566487236139, 0.022379177974295374, 0.9999999999999998, 0.03374254789558027, 0.017255960338680734, 0.07439131716936147, 0.03443273605168204, 0.13014823126413302, 0.03287520595322564, 0.024268645736909535, 0.02534925630583086, 0.019065986103855077, 0.09894019010400074, 0.06700308307581297, 0.08331002323464684, 0.03445001879214869, 0.02638617300370136, 0.043713677694103566, 0.03449627897512518, 0.16047481799176214, 0.021707043414212854, 0.09874390223252565, 0.04652159452916629, 0.03125256877009402, 0.027944753662007334, 0.02385640403128832, 0.08222473484455033, 0.05084501777374595], [0.03151665724059068, 0.03936900496682133, 0.025545948269171916, 0.028171440954443065, 0.0619573257355059, 0.0520584792328089, 0.06581313221962583, 0.028467980186921114, 0.07077751787801828, 0.02442502567684971, 0.026474991678188, 0.02863076531926898, 0.013482004125138928, 0.09841911292697111, 0.02218019532373577, 0.021116263203550503, 0.03374254789558027, 1.0000000000000002, 0.01903419593742145, 0.0676147054713807, 0.029317042427387988, 0.11034810260581532, 0.03143140888561639, 0.02327016865515183, 0.02326968951308742, 0.017299236092343486, 0.08572948146351039, 0.05932929882544014, 0.07707752680126345, 0.026198209525817497, 0.024784012615900543, 0.056424997536385836, 0.03293225759741786, 0.14157894083067182, 0.019999678639101695, 0.09199453202192985, 0.04484231141566549, 0.026654656841168932, 0.025796468576596107, 0.021604325950874987, 0.07422906109227506, 0.03137382919451972], [0.01596295805813951, 0.01904207185712521, 0.016919804000450685, 0.01370973831826939, 0.02986095341306451, 0.02514639347282401, 0.031596539061370645, 0.014017905335899476, 0.034159427606676396, 0.014981150409245227, 0.01258819922293873, 0.011357925835738362, 0.006671732364539766, 0.047885047903829886, 0.010349227821942355, 0.010303044834429639, 0.017255960338680734, 0.01903419593742145, 1.0000000000000002, 0.03215876720627089, 0.01381532062200975, 0.05436755686439874, 0.015412922795772211, 0.011361009718114209, 0.011336191816764504, 0.008333549936315278, 0.041605443985076596, 0.028638550486732837, 0.03699948842740553, 0.013120043032730172, 0.012103001956867183, 0.016861856517667227, 0.01627818855467859, 0.06972962248454076, 0.00973422255760996, 0.04403269923481772, 0.021919473002236546, 0.013075725478234618, 0.01261452889678766, 0.010642416073425878, 0.03616608219462415, 0.015245821209949157], [0.06653009920357413, 0.0857309165858833, 0.05476995406850829, 0.06117911707144513, 0.1449778851380432, 0.13001111419180703, 0.16358713751026246, 0.06278284919317088, 0.16690181056770312, 0.05631381869331305, 0.05991126458791599, 0.04920808224820099, 0.028715694798853653, 0.22656931267676866, 0.04320722596284147, 0.04467234112478082, 0.07439131716936147, 0.0676147054713807, 0.03215876720627089, 1.0, 0.07062995141910766, 0.2529237467149436, 0.06659375447559493, 0.04793104563026376, 0.05269304083750944, 0.0386698225274351, 0.2273524237497388, 0.15888161956296926, 0.18322556725092395, 0.05620259748531506, 0.04886807717004708, 0.07479830545563775, 0.07012230983007345, 0.3061644983940955, 0.04419238495326734, 0.24999372207012088, 0.11502661868247237, 0.05680257822412348, 0.05658081735291732, 0.045627230946793135, 0.1676411318340355, 0.06723399495928621], [0.029231806947803876, 0.03866276061552529, 0.02395712571765319, 0.026671436405810222, 0.05842948755211186, 0.053482930259438434, 0.06781671670310087, 0.02709273969461833, 0.07090867398177844, 0.021314026679401233, 0.026386583739141118, 0.02187694110043609, 0.01173304063396296, 0.11693406567596455, 0.017822183381387947, 0.018982414748640146, 0.03443273605168204, 0.029317042427387988, 0.01381532062200975, 0.07062995141910766, 1.0000000000000002, 0.13280979402767373, 0.027727022075407812, 0.019894311762932743, 0.022273045400841317, 0.017944998867325063, 0.08988189278956457, 0.06109635955248192, 0.07469818905218725, 0.02444429881729129, 0.020660510381908928, 0.032156469580652894, 0.029560481567987823, 0.1476693090772534, 0.01988955236163704, 0.08741447508315975, 0.036357475961134256, 0.0250805999597601, 0.02400522367366945, 0.020912656380551682, 0.0712300589910468, 0.030893851784229945], [0.11077835032100461, 0.14453428687374928, 0.09319353638427164, 0.10064844098382952, 0.2194720168448274, 0.19361426105921398, 0.2486154323846075, 0.10425883514212661, 0.26506221264178065, 0.08485268075679633, 0.09567021027104297, 0.08232998134326167, 0.04573138934449901, 0.45773325977749396, 0.07015495702217113, 0.07296549846462534, 0.13014823126413302, 0.11034810260581532, 0.05436755686439874, 0.2529237467149436, 0.13280979402767373, 1.0, 0.10848152371713578, 0.07998265601936339, 0.08524694890498083, 0.06475722695315161, 0.33151793660787426, 0.2246924903466333, 0.27502060597042904, 0.09402763254057481, 0.08586357747346937, 0.12068943032079028, 0.11318100192582581, 0.5518862637706556, 0.0723451939276264, 0.32386625401721414, 0.14810394887700462, 0.0960943615630929, 0.09116683751507561, 0.07987723967802848, 0.26896940259894425, 0.11604505314136473], [0.031329829128391565, 0.04025439171640523, 0.02529114917167498, 0.027878349176503874, 0.06178726897286266, 0.05151911984207489, 0.06444366073907928, 0.028277894294076896, 0.0697948700631387, 0.02395719854181694, 0.026754631535467064, 0.022762592871324535, 0.013108410469762837, 0.09669323375122825, 0.02093859069770804, 0.02114100162418293, 0.03287520595322564, 0.03143140888561639, 0.015412922795772211, 0.06659375447559493, 0.027727022075407812, 0.10848152371713578, 1.0000000000000002, 0.022838439026680857, 0.023328119618217028, 0.01695521281577985, 0.08476945517370975, 0.06149017261224141, 0.07519254817788171, 0.02624095963447614, 0.024181236069851078, 0.03375258159497254, 0.03411867885878126, 0.13825503643901357, 0.019816876349425184, 0.09027179750611967, 0.04429500007994698, 0.026737156946828385, 0.02569560302696484, 0.021196264070624544, 0.07363681226065247, 0.030775438063280043], [0.022744979956505824, 0.028293724933270915, 0.018628911351292056, 0.0200784115370499, 0.04409394766175655, 0.037744663625355244, 0.05026572480516147, 0.02040965075370146, 0.049684253259598396, 0.018010096399173618, 0.019017726725339457, 0.01664550297993091, 0.00966433892392974, 0.06978311545870493, 0.015207816467740082, 0.015598669212085236, 0.024268645736909535, 0.02327016865515183, 0.011361009718114209, 0.04793104563026376, 0.019894311762932743, 0.07998265601936339, 0.022838439026680857, 1.0, 0.01677094371300471, 0.01218978575435564, 0.06614004554242621, 0.04401067264699684, 0.05628346614870123, 0.018765812120776326, 0.018089427107261236, 0.02480589399686904, 0.04915559090152212, 0.1005990770544037, 0.014354833468207265, 0.06694608464803113, 0.033256341777468196, 0.01917696808023571, 0.018436887349615776, 0.01644774567376246, 0.055070675667211653, 0.022514558504759457], [0.023542315976830996, 0.02899638112936586, 0.019085547433670972, 0.02117430710537471, 0.0462999719061893, 0.038948845867599884, 0.04884306525314736, 0.021280402488773578, 0.052643637028275236, 0.017917492671282287, 0.01934865840074234, 0.0171339183214719, 0.012574916423226215, 0.07660188823298546, 0.015075850635869258, 0.015507920500933504, 0.02534925630583086, 0.02326968951308742, 0.011336191816764504, 0.05269304083750944, 0.022273045400841317, 0.08524694890498083, 0.023328119618217028, 0.01677094371300471, 0.9999999999999999, 0.012914009870002493, 0.06450916088248905, 0.044373418772145075, 0.05622543752371582, 0.019518045403789475, 0.017794786455598642, 0.02516266056083383, 0.02445808941683099, 0.10463929272467178, 0.014876812221870836, 0.06876600306289818, 0.0323092853231566, 0.019888392612168015, 0.01911014117308977, 0.015917753107248994, 0.055180645854916645, 0.02295037084599535], [0.017292064995466812, 0.021804143622082016, 0.014174702216138882, 0.015862265776844603, 0.03439006018192147, 0.029596460434730874, 0.03742381838521499, 0.01601362831110527, 0.047364963977974905, 0.01289403368148154, 0.014457859219824907, 0.012726490348672388, 0.007180549510112881, 0.05814176328683854, 0.011010663364708928, 0.011266539726728033, 0.019065986103855077, 0.017299236092343486, 0.008333549936315278, 0.0386698225274351, 0.017944998867325063, 0.06475722695315161, 0.01695521281577985, 0.01218978575435564, 0.012914009870002493, 1.0, 0.04939825958997596, 0.03376051358953299, 0.04274719727459735, 0.014551202813237973, 0.012741044156591745, 0.019030370632170526, 0.017707624418510513, 0.07894148571728102, 0.01123836740086806, 0.050959533576569106, 0.023701323193724016, 0.014746962344312114, 0.014261473372104387, 0.011859796260564577, 0.0415429322106295, 0.017203156630803428], [0.08597239301963992, 0.11011634040346119, 0.07005496380633132, 0.07709026003419298, 0.17971240387506046, 0.15716161478933283, 0.34274222884100586, 0.07930194101717586, 0.25349697357382506, 0.06536258659590265, 0.07252462577928742, 0.06446868214763235, 0.03593762538851321, 0.29799578153574735, 0.0546328879912984, 0.05617375913927633, 0.09894019010400074, 0.08572948146351039, 0.041605443985076596, 0.2273524237497388, 0.08988189278956457, 0.33151793660787426, 0.08476945517370975, 0.06614004554242621, 0.06450916088248905, 0.04939825958997596, 1.0, 0.25619703777630026, 0.2231107798192734, 0.0728764452042967, 0.06702800580705777, 0.09421481257082782, 0.08812632696874156, 0.4092770448189599, 0.056189197779342503, 0.3032445994309076, 0.11678734399710933, 0.07328271791106829, 0.07268280709794746, 0.07218605971414592, 0.3477144961012736, 0.08622625072470652], [0.05914099490369381, 0.07522223499998257, 0.04833215415721534, 0.05315617664523483, 0.1300972955998942, 0.11343965524207462, 0.21280308254959304, 0.054449686230190766, 0.15360762305819436, 0.04467581811780054, 0.050174312694089944, 0.04427825976021491, 0.0255037438864717, 0.20333057970011353, 0.03806577379626567, 0.04004800983313107, 0.06700308307581297, 0.05932929882544014, 0.028638550486732837, 0.15888161956296926, 0.06109635955248192, 0.2246924903466333, 0.06149017261224141, 0.04401067264699684, 0.044373418772145075, 0.03376051358953299, 0.25619703777630026, 1.0, 0.1633289196843248, 0.05021769292821044, 0.04445894878987989, 0.06474051996052953, 0.06087585908509974, 0.2810441247133264, 0.03834988196632956, 0.18333750557438627, 0.08097478121415085, 0.05046387364325218, 0.05448957292927823, 0.041346891153442554, 0.16299540595167772, 0.0592550898249144], [0.07583524141781998, 0.09585794127593901, 0.06200195522813515, 0.06777967210113768, 0.15289115386430685, 0.13280876832062194, 0.16999219415603098, 0.06912809135535603, 0.2009836466229883, 0.05837600045130576, 0.06398943983450861, 0.05668215392936427, 0.03263886637469545, 0.2442755713261183, 0.049619155633998845, 0.050449872795180914, 0.08331002323464684, 0.07707752680126345, 0.03699948842740553, 0.18322556725092395, 0.07469818905218725, 0.27502060597042904, 0.07519254817788171, 0.05628346614870123, 0.05622543752371582, 0.04274719727459735, 0.2231107798192734, 0.1633289196843248, 1.0000000000000002, 0.06409231748957686, 0.05709992540937054, 0.08331837421741989, 0.07792044152175792, 0.34751307850108965, 0.048845071342366875, 0.5405202962083165, 0.21515063709528032, 0.06438222939189849, 0.06307296307907309, 0.05295549327360684, 0.18614274504047995, 0.07628825587029445], [0.026183580316338533, 0.032827512813637605, 0.02140437438049086, 0.02527338704994918, 0.051564881321266215, 0.04365861497202805, 0.055328087841706335, 0.02468758670845267, 0.05996258925387346, 0.020028914425320194, 0.022596333028729546, 0.019438526055163944, 0.011075130158345369, 0.08474061959784529, 0.01715608448657157, 0.01730884961722359, 0.03445001879214869, 0.026198209525817497, 0.013120043032730172, 0.05620259748531506, 0.02444429881729129, 0.09402763254057481, 0.02624095963447614, 0.018765812120776326, 0.019518045403789475, 0.014551202813237973, 0.0728764452042967, 0.05021769292821044, 0.06409231748957686, 0.9999999999999998, 0.019983125943822833, 0.032923694863514506, 0.02725779112759947, 0.12237591524872518, 0.016730941965779313, 0.0763024242962168, 0.0361807942860405, 0.022793841438091718, 0.0218147468875889, 0.018065875535658783, 0.06256106836824915, 0.026454005984069908], [0.0242634863433639, 0.029402078536432216, 0.01957759611991643, 0.020935355380814223, 0.04626064621089999, 0.038764883661334903, 0.048828356304660966, 0.021666228536092333, 0.05290420939429013, 0.019249236508094295, 0.019791145534405613, 0.02267153005235065, 0.010156524417476461, 0.07497746194398369, 0.018371714269165857, 0.016289876370127323, 0.02638617300370136, 0.024784012615900543, 0.012103001956867183, 0.04886807717004708, 0.020660510381908928, 0.08586357747346937, 0.024181236069851078, 0.018089427107261236, 0.017794786455598642, 0.012741044156591745, 0.06702800580705777, 0.04445894878987989, 0.05709992540937054, 0.019983125943822833, 1.0, 0.025923380994828518, 0.025696085014525263, 0.11125801526969255, 0.014899987827209697, 0.06796111409438618, 0.03497264181181283, 0.020500055110188074, 0.019637984910567837, 0.017349106941964485, 0.056295012985750084, 0.023943194285123728], [0.03398716865458982, 0.042903144989088794, 0.02778796807137358, 0.04389903792172852, 0.06672618179566922, 0.056936026539384565, 0.07147312718162581, 0.14251207616809677, 0.07686566865741715, 0.026269348608216985, 0.028175171147334456, 0.025004763344798977, 0.014355129610674009, 0.11166373224126597, 0.0222899186568757, 0.02283907331294732, 0.043713677694103566, 0.056424997536385836, 0.016861856517667227, 0.07479830545563775, 0.032156469580652894, 0.12068943032079028, 0.03375258159497254, 0.02480589399686904, 0.02516266056083383, 0.019030370632170526, 0.09421481257082782, 0.06474051996052953, 0.08331837421741989, 0.032923694863514506, 0.025923380994828518, 1.0, 0.03584339063943427, 0.15341170911505642, 0.02191756655410427, 0.09929838401294329, 0.04855917992949748, 0.03047987273112228, 0.027906953484798415, 0.023392816777911794, 0.08070792005352265, 0.03402211306152966], [0.03287429242156608, 0.04032369138045869, 0.026465185583688634, 0.029687194469120905, 0.06488381730758007, 0.05373488851870604, 0.06798078144224082, 0.03293644244296265, 0.07257110692380826, 0.025203284678920416, 0.02782199036658427, 0.023640655101441786, 0.022711510541830262, 0.10162780703900248, 0.02154032148397881, 0.022411670117470316, 0.03449627897512518, 0.03293225759741786, 0.01627818855467859, 0.07012230983007345, 0.029560481567987823, 0.11318100192582581, 0.03411867885878126, 0.04915559090152212, 0.02445808941683099, 0.017707624418510513, 0.08812632696874156, 0.06087585908509974, 0.07792044152175792, 0.02725779112759947, 0.025696085014525263, 0.03584339063943427, 1.0000000000000002, 0.14325098081018528, 0.02081841448139781, 0.09450827243932042, 0.0463057373352485, 0.02763583528665456, 0.026684736057441243, 0.03480845914589492, 0.07660663485187459, 0.03183671737555141], [0.1416974872252486, 0.1775943691700019, 0.11336688587947695, 0.12358157884297678, 0.2714875883335937, 0.24581306300391936, 0.3063699723790095, 0.12992525492722737, 0.3399219518647933, 0.10693624266422651, 0.11788744107755551, 0.10716223139783253, 0.06071613380232968, 0.5033262657327233, 0.09224965531848349, 0.0934295823004606, 0.16047481799176214, 0.14157894083067182, 0.06972962248454076, 0.3061644983940955, 0.1476693090772534, 0.5518862637706556, 0.13825503643901357, 0.1005990770544037, 0.10463929272467178, 0.07894148571728102, 0.4092770448189599, 0.2810441247133264, 0.34751307850108965, 0.12237591524872518, 0.11125801526969255, 0.15341170911505642, 0.14325098081018528, 1.0, 0.09005764986307457, 0.4069571180584759, 0.18805466724346978, 0.12116828427127346, 0.11765803158532741, 0.10211386532032586, 0.3485302370560408, 0.14374825744286698], [0.019997642422751528, 0.025131172770735587, 0.01605827011262845, 0.018020714333452547, 0.03983755416304234, 0.033982367271759274, 0.04253863256828498, 0.018285193998405454, 0.046128367850856104, 0.015216810102332274, 0.016730016051402778, 0.014628367085631665, 0.008342789452796278, 0.06518822342363945, 0.012913197796358836, 0.013059623807704748, 0.021707043414212854, 0.019999678639101695, 0.00973422255760996, 0.04419238495326734, 0.01988955236163704, 0.0723451939276264, 0.019816876349425184, 0.014354833468207265, 0.014876812221870836, 0.01123836740086806, 0.056189197779342503, 0.03834988196632956, 0.048845071342366875, 0.016730941965779313, 0.014899987827209697, 0.02191756655410427, 0.02081841448139781, 0.09005764986307457, 1.0, 0.05857925484978202, 0.027347483110277803, 0.01706012062956521, 0.016389461573624517, 0.013595858061659178, 0.04778104539832294, 0.019701407190931313], [0.09095400592124175, 0.1143050310931026, 0.07342172000729562, 0.08209562090730714, 0.18355133864896359, 0.16047706561082134, 0.20878113284385455, 0.08269895992676911, 0.2474744493128145, 0.06947809326702128, 0.07635401939163589, 0.06676225288088676, 0.038787043699212494, 0.2903250546502607, 0.05949029718312664, 0.06024033891838518, 0.09874390223252565, 0.09199453202192985, 0.04403269923481772, 0.24999372207012088, 0.08741447508315975, 0.32386625401721414, 0.09027179750611967, 0.06694608464803113, 0.06876600306289818, 0.050959533576569106, 0.3032445994309076, 0.18333750557438627, 0.5405202962083165, 0.0763024242962168, 0.06796111409438618, 0.09929838401294329, 0.09450827243932042, 0.4069571180584759, 0.05857925484978202, 1.0000000000000002, 0.28745844232538587, 0.07673347696681512, 0.07580112494771148, 0.06235578808397901, 0.24532617291847553, 0.08991741155862744], [0.04403965905185058, 0.05468096949502886, 0.03629038293063621, 0.039581959240507496, 0.0885600302551314, 0.07278901488018505, 0.08938872308655964, 0.03957147805210408, 0.09508978772785642, 0.035490944670052454, 0.03667688777598203, 0.03212067264156391, 0.01898153925459111, 0.12899366112500602, 0.029952874262000734, 0.029942332975133792, 0.04652159452916629, 0.04484231141566549, 0.021919473002236546, 0.11502661868247237, 0.036357475961134256, 0.14810394887700462, 0.04429500007994698, 0.033256341777468196, 0.0323092853231566, 0.023701323193724016, 0.11678734399710933, 0.08097478121415085, 0.21515063709528032, 0.0361807942860405, 0.03497264181181283, 0.04855917992949748, 0.0463057373352485, 0.18805466724346978, 0.027347483110277803, 0.28745844232538587, 1.0, 0.03739601786016348, 0.03723437634639826, 0.030230632206616977, 0.10771791515668051, 0.04407816234827056], [0.027057096929003883, 0.03302611253624556, 0.021837751484882532, 0.02435410536604381, 0.052512911882649185, 0.04427570171613459, 0.055518154684955114, 0.02508297376165967, 0.060093953108754365, 0.020317447123589592, 0.022046896266489265, 0.019609366578707717, 0.011152174528567742, 0.08632128831899256, 0.01736245531747586, 0.017536970960836947, 0.03125256877009402, 0.026654656841168932, 0.013075725478234618, 0.05680257822412348, 0.0250805999597601, 0.0960943615630929, 0.026737156946828385, 0.01917696808023571, 0.019888392612168015, 0.014746962344312114, 0.07328271791106829, 0.05046387364325218, 0.06438222939189849, 0.022793841438091718, 0.020500055110188074, 0.03047987273112228, 0.02763583528665456, 0.12116828427127346, 0.01706012062956521, 0.07673347696681512, 0.03739601786016348, 1.0, 0.021883937650733896, 0.018250872834667895, 0.06304516471945035, 0.026157016220128705], [0.025831064053697617, 0.03201073333492582, 0.020849456675243294, 0.023108761242218497, 0.05077071001300846, 0.04324356004006511, 0.06154706235891531, 0.02348642059089202, 0.059377918784649264, 0.019670154574229312, 0.021248645278679514, 0.01904658703585116, 0.01083778677577958, 0.08180910676963772, 0.01700405062644495, 0.01702210987941842, 0.027944753662007334, 0.025796468576596107, 0.01261452889678766, 0.05658081735291732, 0.02400522367366945, 0.09116683751507561, 0.02569560302696484, 0.018436887349615776, 0.01911014117308977, 0.014261473372104387, 0.07268280709794746, 0.05448957292927823, 0.06307296307907309, 0.0218147468875889, 0.019637984910567837, 0.027906953484798415, 0.026684736057441243, 0.11765803158532741, 0.016389461573624517, 0.07580112494771148, 0.03723437634639826, 0.021883937650733896, 1.0, 0.017654431138055978, 0.06263812116054825, 0.025391225117632275], [0.021416162760757158, 0.02737066012106327, 0.01745077549974613, 0.018891668580228737, 0.04134463566680154, 0.03631528946982599, 0.04536337730636131, 0.01985174236779314, 0.049207706672333554, 0.01955048955241662, 0.019948852872841098, 0.01601622170058907, 0.009155032545604012, 0.07102357629123639, 0.014208978254103671, 0.014277646711913686, 0.02385640403128832, 0.021604325950874987, 0.010642416073425878, 0.045627230946793135, 0.020912656380551682, 0.07987723967802848, 0.021196264070624544, 0.01644774567376246, 0.015917753107248994, 0.011859796260564577, 0.07218605971414592, 0.041346891153442554, 0.05295549327360684, 0.018065875535658783, 0.017349106941964485, 0.023392816777911794, 0.03480845914589492, 0.10211386532032586, 0.013595858061659178, 0.06235578808397901, 0.030230632206616977, 0.018250872834667895, 0.017654431138055978, 1.0, 0.05113606708869627, 0.02188281140277145], [0.07413242719920399, 0.09207140695380242, 0.059603163209022904, 0.06630458808012411, 0.1919623192050815, 0.13069673448067012, 0.22020109377402555, 0.06778030355457221, 0.21255992219862363, 0.056211954625447015, 0.061465435150047654, 0.054563930483606846, 0.03165566134506786, 0.24535204074572764, 0.04782083965443127, 0.0485842676903483, 0.08222473484455033, 0.07422906109227506, 0.03616608219462415, 0.1676411318340355, 0.0712300589910468, 0.26896940259894425, 0.07363681226065247, 0.055070675667211653, 0.055180645854916645, 0.0415429322106295, 0.3477144961012736, 0.16299540595167772, 0.18614274504047995, 0.06256106836824915, 0.056295012985750084, 0.08070792005352265, 0.07660663485187459, 0.3485302370560408, 0.04778104539832294, 0.24532617291847553, 0.10771791515668051, 0.06304516471945035, 0.06263812116054825, 0.05113606708869627, 1.0000000000000002, 0.07325204469466873], [0.030798225359168065, 0.03894700017324689, 0.05869231036722231, 0.0274686214759716, 0.0602736578802967, 0.05193286262898654, 0.06549847728238417, 0.0290406390761364, 0.07022013083945233, 0.02399839470862073, 0.026047514320094934, 0.023010996881306253, 0.012939144353344385, 0.10060995727245398, 0.020162901952240356, 0.020866970424025785, 0.05084501777374595, 0.03137382919451972, 0.015245821209949157, 0.06723399495928621, 0.030893851784229945, 0.11604505314136473, 0.030775438063280043, 0.022514558504759457, 0.02295037084599535, 0.017203156630803428, 0.08622625072470652, 0.0592550898249144, 0.07628825587029445, 0.026454005984069908, 0.023943194285123728, 0.03402211306152966, 0.03183671737555141, 0.14374825744286698, 0.019701407190931313, 0.08991741155862744, 0.04407816234827056, 0.026157016220128705, 0.025391225117632275, 0.02188281140277145, 0.07325204469466873, 0.9999999999999999]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkO85LJy3wj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2922d9b5-4d2c-4c7b-f591-af0385794a37"
      },
      "source": [
        "model = Doc2Vec(taggedDocs, vector_size=42,  min_count=1, size=300, workers=1, window=5, max_vocab_size=2000, seed=randomSeed)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kw-hunbBY3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "72499f86-f301-4a58-d1c4-5d3a518cba72"
      },
      "source": [
        "allscores = []\n",
        "for file in allFilenames:\n",
        "  docVector = model.infer_vector(taggedDoc[file])\n",
        "  mostSim=model.dv.most_similar(positive=[docVector])\n",
        "  dictionarySim = dict(mostSim) \n",
        "  scores = []\n",
        "  for f in allFilenames:\n",
        "    if f not in dictionarySim:\n",
        "      scores.append(0)\n",
        "    else:\n",
        "\n",
        "      scores.append(dictionarySim[f])\n",
        "  allscores.append(scores)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c5815524fa7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mallscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallFilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdocVector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaggedDoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mmostSim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocVector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdictionarySim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmostSim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NSm0MnIu3tD"
      },
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "print(allscores)\n",
        "\n",
        "# mat = multilabel_confusion_matrix(allscores, allscores)\n",
        "# sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "#             xticklabels=allFilenames, yticklabels=allFilenames)\n",
        "# plt.xlabel('true label')\n",
        "# plt.ylabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eznal8dcWlSn"
      },
      "source": [
        "**ANSWER:**\n",
        "The heatmap was not able to be created but the score were printed out manually. As wellas doc2vec did not compile. Based on an assumption, I would say doc2vec would have preformed better simply because most of the calculations in the first implementation did not score higher than 0.1% except for when a filename is matched with itself. If my assumption that doc2vec performs better I believe this would have everything to do with tokenization as the implementations to score the words should not have any impact. The tokens may have had the largest deviation in quality that impacted the scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv9yptptlc2M"
      },
      "source": [
        "Question 3) (30 points) Using the Homework 2 dataset. Use SpaCy to extract the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I54ThY30755N"
      },
      "source": [
        "import spacy\n",
        "from nltk import bigrams, trigrams\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATUZuEKo784t"
      },
      "source": [
        "from collections import Counter, defaultdict\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9HifDZJuCfS"
      },
      "source": [
        "b) Write a function to generate all unique trigrams from all documents in the dataset. The\n",
        "input of this function should be the concatenated dataset and the output should be the\n",
        "list of trigrams and their frequency. Display the top 10 most common trigrams and their\n",
        "frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXqGCtkUs0pp"
      },
      "source": [
        "def buildTrimodel(all_content):\n",
        "  trimodel = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "  for content in all_content:\n",
        "    sentences = nltk.sent_tokenize(content)\n",
        "    for sentence in sentences:\n",
        "      doc = nlp(sentence)\n",
        "      for w1, w2, w3 in trigrams(doc, pad_right=True, pad_left=True):\n",
        "        trimodel[(w1, w2)][w3] += 1\n",
        "  return trimodel"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W2KCK2unXng"
      },
      "source": [
        "def getSmallestItem(items):\n",
        "  keys = list(items.keys())\n",
        "  smallestVal = items[keys[0]]\n",
        "  smallestKey = keys[0]\n",
        "  for key in keys:\n",
        "    val = items[key]\n",
        "    if val < smallestVal:\n",
        "      smallestVal = val\n",
        "      smallestKey = key\n",
        "  return (smallestKey, smallestVal)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDdUtu3_lQr6"
      },
      "source": [
        "def buildTrigram(all_content):\n",
        "  trimodel = buildTrimodel(all_content)\n",
        "  tri_ten = {}\n",
        "  for w1_w2 in trimodel:\n",
        "    total_count = float(sum(trimodel[w1_w2].values()))\n",
        "    #fill it up\n",
        "    if len(tri_ten) < 10:\n",
        "      tri_ten[w1_w2] = total_count\n",
        "    else:\n",
        "      # replace smallest if large enough\n",
        "      smallestKey, smallestVal = getSmallestItem(tri_ten)\n",
        "      if total_count > smallestVal:\n",
        "        tri_ten.pop(smallestKey)\n",
        "        tri_ten[w1_w2] = total_count\n",
        "  return tri_ten"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P36VjK_km5pg",
        "outputId": "7b3151c2-63d3-4fd6-d2ff-8d4ac48c7e1a"
      },
      "source": [
        "print(buildTrigram(shakespearContent))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{(None, None): 78295.0, (None, The): 1.0, (The, Winter): 1.0, (Winter, 's): 1.0, ('s, Tale): 1.0, (Tale, \n",
            "): 1.0, (\n",
            ", by): 1.0, (by, William): 1.0, (William, Shakespeare): 1.0, (Shakespeare, \n",
            "): 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnfAaDmdlgiz"
      },
      "source": [
        "a) Write a function to generate all unique bigrams from all documents in the dataset. The\n",
        "input of this function should be the concatenated dataset and the output should be the\n",
        "list of bigrams and their frequency. Display the top 10 most common bigrams and their\n",
        "frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct-vzPevuMNh"
      },
      "source": [
        "def buildBimodel(all_content):\n",
        "  bimodel = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "  for content in all_content:\n",
        "    sentences = nltk.sent_tokenize(content)\n",
        "    for sentence in sentences:\n",
        "      doc = nlp(sentence)\n",
        "      for w1, w2 in bigrams(doc, pad_right=True, pad_left=True):\n",
        "        bimodel[w1][w2] += 1\n",
        "  return bimodel"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roa24Mtol4Dp"
      },
      "source": [
        "def buildBigram(all_content):\n",
        "  bimodel = buildBimodel(all_content)\n",
        "  bi_ten = {}\n",
        "  for w1 in bimodel:\n",
        "    total_count = float(sum(bimodel[w1].values()))\n",
        "    #fill it up\n",
        "    if len(bi_ten) < 10:\n",
        "      bi_ten[w1] = total_count\n",
        "    else:\n",
        "      # replace smallest if large enough\n",
        "      smallestKey, smallestVal = getSmallestItem(bi_ten)\n",
        "      if total_count > smallestVal:\n",
        "        bi_ten.pop(smallestKey)\n",
        "        bi_ten[w1] = total_count\n",
        "  return bi_ten"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Ud0P2YzbK6"
      },
      "source": [
        "print(buildBigram(shakespearContent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuYoY51jzsM9"
      },
      "source": [
        "c) Write a function to extract all unique NOUN and VERB tokens. The input of this function\n",
        "should be the concatenated dataset and the output should be two lists: one of the NOUN\n",
        "tokens and their frequency, the other list should be the VERB tokens and their counts.\n",
        "Display the top 10 most common NOUN and VERB tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFWRoQs8ztaI"
      },
      "source": [
        "def posFinder(all_content):\n",
        "  nounCounter = {}\n",
        "  verbCounter = {}\n",
        "  ntop_ten = {}\n",
        "  vtop_ten = {}\n",
        "  for content in all_content[:3]:\n",
        "    sentences = nltk.sent_tokenize(content)\n",
        "    for sentence in sentences:\n",
        "      doc = nlp(sentence)\n",
        "      for t in doc:\n",
        "        pos = t.pos_\n",
        "        \n",
        "        word = t.text.strip().lower()\n",
        "        if pos == \"NOUN\":\n",
        "          if word in nounCounter:\n",
        "            nounCounter[word] += 1\n",
        "          else:\n",
        "            nounCounter[word] = 1\n",
        "        elif pos == \"VERB\":\n",
        "          if word in verbCounter:\n",
        "            verbCounter[word] += 1\n",
        "          else:\n",
        "            verbCounter[word] = 1\n",
        "  nkeys = nounCounter.keys()\n",
        "  vkeys = verbCounter.keys()\n",
        "  for key in nkeys:\n",
        "    if len(ntop_ten) < 10:\n",
        "      ntop_ten[key] = nounCounter[key]\n",
        "    else:\n",
        "      smallestKey, smallestVal = getSmallestItem(ntop_ten)\n",
        "      count = nounCounter[key]\n",
        "      if count > smallestVal:\n",
        "        ntop_ten.pop(smallestKey)\n",
        "        ntop_ten[key] = count\n",
        "  vkeys = verbCounter.keys()\n",
        "  for key in vkeys:\n",
        "    if len(vtop_ten) < 10:\n",
        "      vtop_ten[key] = verbCounter[key]\n",
        "    else:\n",
        "      smallestKey, smallestVal = getSmallestItem(vtop_ten)\n",
        "      count = verbCounter[key]\n",
        "      if count > smallestVal:\n",
        "        vtop_ten.pop(smallestKey)\n",
        "        vtop_ten[key] = count\n",
        "  return(ntop_ten, vtop_ten)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGvWog-53CwK"
      },
      "source": [
        "posFinder(shakespearContent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9XktNI88vyO"
      },
      "source": [
        "d) What do you think the most common bigrams and trigrams could be useful for? There is\n",
        "a particular method we have seen in this class to characterize a corpus that could benefit\n",
        "from having these bigrams/trigrams when the underlying text corpus can’t be shared.\n",
        "Please talk about this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0gcdaPPCBxn"
      },
      "source": [
        "It would be useful for mapping words to other concepts/clustering, showing relationships between corpuses but not actually exposing the corpuses. Providing a perspective on the data from its key words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSFEc1SF84Qv"
      },
      "source": [
        "Question 4) (30 points) Using the dataset: Ask0729, found in Exam files, write two functions to\n",
        "extract all dates found in this dataset. The input of these functions should take the dataset as\n",
        "input, and output a list of dates. You should use two different methods, one per function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgTV52aI-Gm-"
      },
      "source": [
        "!mkdir -p ask\n",
        "!unzip -n -d ask \"/content/Ask0729.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzAnLyoh871b"
      },
      "source": [
        "a) First method: using SpaCy (this is a big enough hint)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPUSTm6M-6Rp"
      },
      "source": [
        "ask_content = open(str(\"/content/ask/Ask0729-fixed.txt\"), 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxkylTzKMfQR"
      },
      "source": [
        "# months\n",
        "months = [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1fXWauiO6AT"
      },
      "source": [
        "def build_date(one, two, three):\n",
        "  if len(three) == 0:\n",
        "    return one+\" \"+two\n",
        "  return one+\" \"+two+\" \"+three"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33Rtdltt-l53"
      },
      "source": [
        "#possible combos: M D Y, M Y, D M Y\n",
        "def getDatesUsingSpaCy(content):\n",
        "  spacy_dates = []\n",
        "  second = [\"\", \"\"]\n",
        "  first = [\"\", \"\"]\n",
        "  for word in content.split():\n",
        "    doc = nlp(word)\n",
        "    for t in doc:\n",
        "      row = [t.text, t.pos_]\n",
        "      if first[1]  == \"NUM\": #starts with day\n",
        "        if second[1] == \"PROPN\":\n",
        "          # make sure it is a month\n",
        "          lower_second = second[0].lower()\n",
        "          for m in months:\n",
        "            if lower_second.startswith(m):\n",
        "              if row[1] == \"NUM\":\n",
        "                spacy_dates.append(build_date(first[0], second[0], row[0]))\n",
        "              else:\n",
        "                spacy_dates.append(build_date(first[0], second[0], \"\"))\n",
        "      elif first[1]  == \"PROPN\": #starts with month\n",
        "        lower_first = first[0].lower()\n",
        "        for m in months:\n",
        "          if lower_second.startswith(m):\n",
        "            if second[1] == \"NUM\":\n",
        "              if row[1] == \"NUM\":\n",
        "                spacy_dates.append(build_date(first[0], second[0], row[0]))\n",
        "              else:\n",
        "                spacy_dates.append(build_date(first[0], second[0], \"\"))\n",
        "      first = second\n",
        "      second = row\n",
        "  return spacy_dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8njJdaKgB4TH"
      },
      "source": [
        "print(getDatesUsingSpaCy(ask_content))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svefCv7qQTVZ"
      },
      "source": [
        "b) Second method: using regular expressions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQqJoIUWQS7D"
      },
      "source": [
        "import re\n",
        "def getDatesUsingRegex(content):\n",
        "  day_pattern = \"\\w*\\s?([0-9]|0[1-9]|[1-2][0-8]|29|3[0-1])\\s?\\w*\"\n",
        "  month_pattern = \"\\w*\\s?(jan|january|feb|february|mar|march|apr|april|may|jun|june|jul|july|aug|august|sep|september|oct|october|nov|november|dec|december)\\s?\\w*\"\n",
        "  year_pattern = \"\\w*\\s?(18[0-9][0-9]|19[0-9][0-9]|200[0-9])\\s?\\w*\"\n",
        "  compileDay = re.compile(day_pattern)\n",
        "  compileMonth = re.compile(month_pattern)\n",
        "  compileYear = re.compile(year_pattern)\n",
        "  dates = []\n",
        "  buildDate = \"\"\n",
        "  for raw_word in content.split():\n",
        "    word = raw_word.lower().strip()\n",
        "    matchDay = compileDay.match(raw_word)\n",
        "    matchMonth = compileMonth.match(raw_word)\n",
        "    matchYear = compileYear.match(raw_word)\n",
        "    if matchDay:\n",
        "      buildDate += word\n",
        "    elif matchMonth:\n",
        "      buildDate += word\n",
        "    elif matchYear:\n",
        "      buildDate += word\n",
        "  dates.append(buildDate)\n",
        "  buildDate = \"\"\n",
        "  return dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chPII_Pd9uwE"
      },
      "source": [
        "print(getDatesUsingRegex(ask_content))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKgPAeuL-3z4"
      },
      "source": [
        "**ANSWER:**\n",
        "\n",
        "The better approach was the SpaCy, because the parsing is much more organized and has better identifiers, such as Proper nouns and num. That allowed me to narrow down my list to search for. REgex did not produce what was necessary as the pattern became too complex. I would use both combined, and not purely one or the other. Sometimes the indicators of what a date would produce false positives like Houston 2007. Regex would then allow for me to filter that out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTPbvliIXwnK"
      },
      "source": [
        "Question 5) (30 points) Train an LSTM model to classify the Cornell Movie Review data\n",
        "using the polarity_dataset V2.0. You can use the code for class 19, but take a note that\n",
        "you will have to adapt some of the parameters like: Review size = 450, epochs=5. You will use\n",
        "85% of the dataset for training, and 15% for testing. Once you build the model, please display\n",
        "the sklearn classification report. What are you noticing here? Anything unexpected? How does\n",
        "this model compare to the one built with the IMDB dataset in class? Any ideas on how to\n",
        "improve it?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuoF7Y5vA73_"
      },
      "source": [
        "!mkdir -p lsmt\n",
        "!wget -nc http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz /content/\n",
        "# !gunzip /content/review_polarity.tar.gz\n",
        "!tar -xvzf /content/review_polarity.tar.gz -C /content/lsmt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3OHJSnLd0Sj"
      },
      "source": [
        "import pandas as pd\n",
        "# Supress deprecation warnings\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KJ2bN-I6c8i"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pos_df = []\n",
        "neg_df = []\n",
        "pos_num = []\n",
        "neg_num = []\n",
        "class_names=[\"negative\", \"positive\"]\n",
        "polarity = [\"neg/\", \"pos/\"]\n",
        "path = \"/content/lsmt/txt_sentoken/\"\n",
        "for p in polarity:\n",
        "  for filename in os.listdir(path+p):\n",
        "    filepath = path+p+filename\n",
        "    file = open(filepath, 'r')\n",
        "    content = file.read()\n",
        "    split_content = content.split()\n",
        "    if(p == \"pos/\"):\n",
        "      pos_df.append(content)\n",
        "      pos_num.append(1)\n",
        "    else:\n",
        "      neg_df.append(content)\n",
        "      neg_num.append(0)\n",
        "\n",
        "positivePanda = pd.DataFrame({\"polarity\":pos_num, \"text\":pos_df})\n",
        "negativePanda = pd.DataFrame({\"polarity\":neg_num, \"text\":neg_df})\n",
        "frames = [positivePanda, negativePanda]\n",
        "df = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcFWtYCQogU9"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIFSi0IxF3X7"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSrd55cOF4L9"
      },
      "source": [
        "vocab_size=10000\n",
        "vectorizer = TfidfVectorizer(max_features=vocab_size)\n",
        "vectorizer = TfidfVectorizer(max_features=vocab_size)\n",
        "vectors = vectorizer.fit_transform(df.text)\n",
        "word_id_pair = vectorizer.vocabulary_\n",
        "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "words_df.head()\n",
        "X = words_df\n",
        "y = df.polarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Goe0wWMk0T"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "A_X_train, A_X_test, A_y_train, A_y_test = train_test_split(X, y, train_size=0.85, random_state=12345)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RspJhYzlF_Wp"
      },
      "source": [
        "# All the imports!\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from numpy import array\n",
        "import re\n",
        "import random\n",
        "\n",
        "randomSeed = 12345\n",
        "tf.random.set_seed(randomSeed)\n",
        "random.seed(randomSeed)\n",
        "np.random.seed(randomSeed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RmXxGU4V67F"
      },
      "source": [
        "# need to extract words from difficult text\n",
        "getWord = \"[0-9.!:(@)?\\\\-\\*\\#]*([a-zA-Z]+)[0-9.(@:)!?\\\\-\\*\\#]*\"\n",
        "compile = re.compile(getWord)\n",
        "\n",
        "#convert text to ints\n",
        "intTweets = []\n",
        "for tweet in df.text:\n",
        "  split = tweet.split(\" \")\n",
        "  wordInt = []\n",
        "  for raw_word in split:\n",
        "    word = raw_word.lower()\n",
        "    if word not in word_id_pair:\n",
        "      match = compile.match(word)\n",
        "      if match:\n",
        "        grabbedWord = match.group(1)\n",
        "        if grabbedWord in word_id_pair:\n",
        "          wordInt.append(word_id_pair[grabbedWord])\n",
        "        else:\n",
        "          randomValForWord = random.random()\n",
        "          word_id_pair[word] = randomValForWord\n",
        "          wordInt.append(randomValForWord)\n",
        "    else:\n",
        "      wordInt.append(word_id_pair[word])\n",
        "  intTweets.append(wordInt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhXSpRXtR42z"
      },
      "source": [
        "#need to provide uniform length\n",
        "#preset to 450\n",
        "review_length = 450\n",
        "\n",
        "# Padding / truncated our reviews\n",
        "intTweets_padded = sequence.pad_sequences(intTweets, maxlen = review_length)\n",
        "\n",
        "# split the tweet using the same randomseed\n",
        "# a 85% training, 15 test\n",
        "tweets_train, tweets_test, y_train, y_test = train_test_split(intTweets_padded, y, train_size=0.85, random_state=randomSeed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nmO8M4aCKwT"
      },
      "source": [
        "# We begin by defining the a empty stack. We'll use this for building our \n",
        "# network, later by layer.\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# The Embedding Layer provides a spatial mapping (or Word Embedding) of all the \n",
        "# individual words in our training set. Words close to one another share context \n",
        "# and or meaning. This spatial mapping is learning during the training process.\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = vocab_size, # The size of our vocabulary \n",
        "        output_dim = 32, # Dimensions to which each words shall be mapped\n",
        "        input_length = review_length # Length of input sequences\n",
        "    )\n",
        ")\n",
        "\n",
        "# Dropout layers fight overfitting and forces the model to learn multiple \n",
        "# representations of the same data by randomly disabling neurons in the \n",
        "# learning phase.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# We are using a fast version of LSTM whih is optimised for GPUs. This layer \n",
        "# looks at the sequence of words in the review, along with their word embeddings\n",
        "# and uses both of these to determine to sentiment of a given review.\n",
        "model.add(\n",
        "    tf.keras.layers.LSTM(\n",
        "        units=32 # 32 LSTM units in this layer\n",
        "    )\n",
        ")\n",
        "\n",
        "# Add a second dropout layer with the same aim as the first.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# All LSTM units are connected to a single node in the dense layer. A sigmoid \n",
        "# activation function determines the output from this node - a value \n",
        "# between 0 and 1. Closer to 0 indicates a negative review. Closer to 1 \n",
        "# indicates a positive review.\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1, # Single unit\n",
        "        activation='sigmoid' # Sigmoid activation function (output from 0 to 1)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
        "    metrics=['accuracy']) # reporting metric\n",
        "\n",
        "# Display a summary of the models structure\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEN1vV4nG1V3"
      },
      "source": [
        "# Train the LSTM on the training data\n",
        "history = model.fit(\n",
        "\n",
        "    # Training data : features (review) and classes (positive or negative)\n",
        "    tweets_train, y_train,\n",
        "                    \n",
        "    # Number of samples to work through before updating the \n",
        "    # internal model parameters via back propagation. The \n",
        "    # higher the batch, the more memory you need.\n",
        "    batch_size=128, \n",
        "\n",
        "    # An epoch is an iteration over the entire training data.\n",
        "    epochs=5, \n",
        "    \n",
        "    # The model will set apart his fraction of the training \n",
        "    # data, will not train on it, and will evaluate the loss\n",
        "    # and any model metrics on this data at the end of \n",
        "    # each epoch.\n",
        "    validation_split=0.2,\n",
        "    \n",
        "    verbose=1\n",
        ") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPnfxwbnITqV"
      },
      "source": [
        "# Get Model Predictions for test data\n",
        "from sklearn.metrics import classification_report\n",
        "predicted_classes = model.predict_classes(tweets_test)\n",
        "classRep = (classification_report(y_test, predicted_classes, target_names=class_names))\n",
        "print(classRep)\n",
        "reportArray = (classRep.split())\n",
        "precision = (float(reportArray[19])*100.0)\n",
        "recall = (float(reportArray[20])*100.0)\n",
        "fOne = (float(reportArray[21])*100.0)\n",
        "lsmt_scores = [\"LSMT\", precision, recall, fOne]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At0HmtnfsDqI"
      },
      "source": [
        "**ANSWER:**\n",
        "\n",
        "\n",
        "I noticed a steep drop in precision relative to recall for negative and a steeper drop from recall relative to precision for prositive. It is much less consistent than the IMDB one as that one remained in the high 80s across all scores. This can be improved by better tokenizing the dataset using a corpus that understands the corpus for better context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMVHPajcu1hc"
      },
      "source": [
        "Question 6) (30 points) Use the train.txt file from the PubMed 20K RCT dataset fine-tune a\n",
        "BERT transformer (class 9 code). This task is a bit different as the one seen in class, here the\n",
        "source dataset has FIVE different classes: background, objective, method, result, and\n",
        "conclusion. Once the BERT model is fine-tuned, classify the: test.txt set. Please present the\n",
        "per-class classification report (accuracy, precision, recall, f1-score metrics). Also, present the\n",
        "global metrics - all classes (accuracy, precision, recall, f1-score metrics). Did you model beat the\n",
        "baseline results (https://arxiv.org/pdf/1710.06071.pdf)? What do you think you can do to improve\n",
        "it?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "# else:\n",
        "#     raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FlNn0VyvJDI"
      },
      "source": [
        "!wget -nc https://github.com/Franck-Dernoncourt/pubmed-rct/raw/master/PubMed_20k_RCT/train.txt /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "labels = [\"BACKGROUND\", \"OBJECTIVE\", \"METHODS\", \"RESULTS\", \"CONCLUSIONS\"]\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/train.txt\", delimiter='\\t', header=None, names=['label', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "df['label'].replace({\"BACKGROUND\": labels.index(\"BACKGROUND\")}, inplace=True)\n",
        "df['label'].replace({\"OBJECTIVE\": labels.index(\"OBJECTIVE\")}, inplace=True)\n",
        "df['label'].replace({\"METHODS\": labels.index(\"METHODS\")}, inplace=True)\n",
        "df['label'].replace({\"RESULTS\": labels.index(\"RESULTS\")}, inplace=True)\n",
        "df['label'].replace({\"CONCLUSIONS\": labels.index(\"CONCLUSIONS\")}, inplace=True)\n",
        "df = df.dropna()\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = list(df.label.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, truncation = True, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "print(labels)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "dataset = dataset[:8000]\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3K07VnkNgFh"
      },
      "source": [
        "BertForSequnceCalssificaction consistently failed and I was not able to train and test the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 5, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = randomSeed\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr5xK2LXf0wn"
      },
      "source": [
        "Evaluate TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe55QifgEFF"
      },
      "source": [
        "!wget -nc https://github.com/Franck-Dernoncourt/pubmed-rct/raw/master/PubMed_20k_RCT/test.txt /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wclAklhgEFG"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "labels = [\"BACKGROUND\", \"OBJECTIVE\", \"METHODS\", \"RESULTS\", \"CONCLUSIONS\"]\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/test.txt\", delimiter='\\t', header=None, names=['label', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "df['label'].replace({\"BACKGROUND\": labels.index(\"BACKGROUND\")}, inplace=True)\n",
        "df['label'].replace({\"OBJECTIVE\": labels.index(\"OBJECTIVE\")}, inplace=True)\n",
        "df['label'].replace({\"METHODS\": labels.index(\"METHODS\")}, inplace=True)\n",
        "df['label'].replace({\"RESULTS\": labels.index(\"RESULTS\")}, inplace=True)\n",
        "df['label'].replace({\"CONCLUSIONS\": labels.index(\"CONCLUSIONS\")}, inplace=True)\n",
        "df = df.dropna()\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6LaORjtjB67"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, truncation = True, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrLw-vdciDhh"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8yGHECvg3gb"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}